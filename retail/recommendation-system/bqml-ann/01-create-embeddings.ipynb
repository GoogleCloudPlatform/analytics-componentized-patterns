{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-latency item-to-item recommendation system \n",
    "\n",
    "## Part 1 - Creating embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook is a part of the [**Low-latency item-to-item recommendation system** ML Engineering blueprint](https://github.com/jarokaz/analytics-componentized-patterns/tree/master/retail/recommendation-system/bqml-ann).\n",
    "\n",
    "The blueprint provides guidance and code samples for how to develop and operationalize a near real-time item-to-itme recommendations system that utilizes BigQuery, BigQuery ML and AI Platform ANN Service.\n",
    "\n",
    "This notebook demonstrates how to create item embeddings using BQML Matrix Factorization model and how to export them in the JSONL format compatible with the ANN Service's ingestion schema. In the notebook you go through the following steps.\n",
    "\n",
    "1. Preparing the training data based on the public `bigquery-samples.playlists` dataset.\n",
    "2. Training the BQML Matrix Factorization model. \n",
    "3. Exploring the trained embeddings.\n",
    "4. Exporting the embeddings.\n",
    "\n",
    "Note that training a BigQuery ML Matrix Factorization model requires slot reservations. For more information, you can read up on how to set up flex slots [programmatically](https://medium.com/google-cloud/optimize-bigquery-costs-with-flex-slots-e06ec5e4aa90) or via the [BigQuery UI](https://cloud.google.com/bigquery/docs/reservations-workload-management#getting-started-with-bigquery-reservations).\n",
    "\n",
    "This notebook was designed to run on [AI Platform Notebooks](https://cloud.google.com/ai-platform/notebooks/docs) using the standard TensorFlow 2.3 image.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The example dataset used in the blueprint is the BigQuery public dataset - `bigquery-samples.playlists` - that contains music playlist data, including a song name, a song artist, and the playlists a given song belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the notebook's environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import notebook dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "import google.auth\n",
    "import numpy as np\n",
    "import tensorflow.io as tf_io\n",
    "\n",
    "from concurrent import futures\n",
    "from google.cloud import bigquery\n",
    "from typing import List, Optional, Text, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure GCP environment\n",
    "\n",
    "Set the following constants to the values reflecting your environment:\n",
    "\n",
    "* `PROJECT_ID` - your GCP project ID\n",
    "* `BUCKET_NAME` - a name of the bucket to store exported embeddings. If you prefer to use a pre-existing bucket you can skip the *Create GCS bucket* cell\n",
    "* `BQ_LOCATION` - the BigQuery location\n",
    "* `BQ_DATASET_NAME` - a name of the BigQuery dataset that will host training data and the model. If you prefer to use a pre-existing bucket you can skip the *Create BigQuery dataset* cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jk-mlops-dev'\n",
    "BUCKET_NAME = 'jk-ann-staging'\n",
    "REGION = 'us-central1'\n",
    "BQ_LOCATION = 'US'\n",
    "BQ_DATASET_NAME = 'song_embeddings'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create GCS bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://jk-ann-staging/...\n"
     ]
    }
   ],
   "source": [
    "!gsutil mb -l {REGION} gs://{BUCKET_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create BigQuery dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client(project=PROJECT_ID, location=BQ_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset jk-mlops-dev.song_embeddings already exists\n"
     ]
    }
   ],
   "source": [
    "dataset_id = f'{PROJECT_ID}.{BQ_DATASET_NAME}'\n",
    "\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "dataset.location = BQ_LOCATION\n",
    "\n",
    "try:\n",
    "    client.get_dataset(dataset_id)\n",
    "    print(f'Dataset {dataset_id} already exists')\n",
    "except google.cloud.exceptions.NotFound:\n",
    "    dataset = client.create_dataset(dataset, timeout=30)\n",
    "    print(f'Created dataset: {dataset_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the training data\n",
    "\n",
    "In this section of the notebook you will prepare data for training a Matrix Factorization model. It is a two step process. \n",
    "\n",
    "1. First, you will copy and clean records from the public `bigquery-samples.playlists.playlist` table to your dataset.\n",
    "2. Then, you will compute item co-occurrence. In the context of the playlist data, item co-occurence quantifies how often two songs occur on the same playlists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a helper function to wait for a result of a BigQuery query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_result(query_job):\n",
    "    print(\"Executing query with job ID: {}\".format(query_job.job_id))\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        print(\"\\rQuery executing: {:0.2f}s\".format(time.time() - start_time), end=\"\")\n",
    "        try:\n",
    "            query_job.result(timeout=0.5)\n",
    "            break\n",
    "        except futures.TimeoutError:\n",
    "            continue\n",
    "    print(\"\\nQuery complete after {:0.2f}s\".format(time.time() - start_time))\n",
    "    return query_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the public `playlist` table and copy a subset to your dataset\n",
    "\n",
    "The sample `playlist` dataset contains over 12 million records. Although the quality of embeddings grows with a size of a corpus used to train them, it takes a rather long time to complete training of a Matrix Factorization model on all records.\n",
    "\n",
    "You can control the size of the corpus used for training the model by setting the `number_of_records` variable. To use all records set the variable to `None`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: c339145f-9269-4a33-aad9-013325bd0f87\n",
      "Query executing: 16.01s\n",
      "Query complete after 16.58s\n"
     ]
    }
   ],
   "source": [
    "number_of_records = 3000000\n",
    "\n",
    "query = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{BQ_DATASET_NAME}.playlist`\n",
    "    AS\n",
    "    SELECT DISTINCT\n",
    "        id list_Id, \n",
    "        tracks_data_id track_Id, \n",
    "        tracks_data_title track_title,\n",
    "        tracks_data_artist_name track_artist\n",
    "    FROM `bigquery-samples.playlists.playlist`\n",
    "    WHERE tracks_data_title IS NOT NULL AND tracks_data_id > 0\n",
    "\"\"\"\n",
    "\n",
    "if  isinstance(number_of_records, int) and number_of_records <= 12304975 :\n",
    "    limit_clause = f'LIMIT {number_of_records}'\n",
    "    query = query + limit_clause\n",
    "    \n",
    "query_job = client.query(query)\n",
    "query_job = wait_for_result(query_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the created table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>list_Id</th>\n",
       "      <th>track_Id</th>\n",
       "      <th>track_title</th>\n",
       "      <th>track_artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9354888</td>\n",
       "      <td>3141579</td>\n",
       "      <td>Galvanize</td>\n",
       "      <td>The Chemical Brothers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8085136</td>\n",
       "      <td>2321655</td>\n",
       "      <td>California Dreamin'</td>\n",
       "      <td>The Mamas &amp; The Papas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2233197</td>\n",
       "      <td>5902134</td>\n",
       "      <td>Incense And Peppermints</td>\n",
       "      <td>Strawberry Alarm Clock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1174313</td>\n",
       "      <td>125479</td>\n",
       "      <td>Mary Hartman, Mary Hartman</td>\n",
       "      <td>Television Theme Songs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>884920</td>\n",
       "      <td>574738</td>\n",
       "      <td>Hit The Floor</td>\n",
       "      <td>Bullet for My Valentine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>773635</td>\n",
       "      <td>912580</td>\n",
       "      <td>River In The Road</td>\n",
       "      <td>Queens of the Stone Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9695428</td>\n",
       "      <td>93175</td>\n",
       "      <td>String Quartet No. 2 in D major, K155: I. Allegro</td>\n",
       "      <td>Wolfgang Amadeus Mozart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7914373</td>\n",
       "      <td>1151554</td>\n",
       "      <td>No Woman, No Cry (Live At The Lyceum, London/1...</td>\n",
       "      <td>Bob Marley &amp; The Wailers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4604492</td>\n",
       "      <td>1151565</td>\n",
       "      <td>Jamming</td>\n",
       "      <td>Bob Marley &amp; The Wailers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1407613</td>\n",
       "      <td>1151537</td>\n",
       "      <td>Iron Lion Zion</td>\n",
       "      <td>Bob Marley &amp; The Wailers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   list_Id  track_Id                                        track_title  \\\n",
       "0  9354888   3141579                                          Galvanize   \n",
       "1  8085136   2321655                                California Dreamin'   \n",
       "2  2233197   5902134                            Incense And Peppermints   \n",
       "3  1174313    125479                         Mary Hartman, Mary Hartman   \n",
       "4   884920    574738                                      Hit The Floor   \n",
       "5   773635    912580                                  River In The Road   \n",
       "6  9695428     93175  String Quartet No. 2 in D major, K155: I. Allegro   \n",
       "7  7914373   1151554  No Woman, No Cry (Live At The Lyceum, London/1...   \n",
       "8  4604492   1151565                                            Jamming   \n",
       "9  1407613   1151537                                     Iron Lion Zion   \n",
       "\n",
       "               track_artist  \n",
       "0     The Chemical Brothers  \n",
       "1     The Mamas & The Papas  \n",
       "2    Strawberry Alarm Clock  \n",
       "3    Television Theme Songs  \n",
       "4   Bullet for My Valentine  \n",
       "5   Queens of the Stone Age  \n",
       "6   Wolfgang Amadeus Mozart  \n",
       "7  Bob Marley & The Wailers  \n",
       "8  Bob Marley & The Wailers  \n",
       "9  Bob Marley & The Wailers  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    SELECT * \n",
    "    FROM\n",
    "    `{BQ_DATASET_NAME}.playlist`\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a view to abstract the `playlist` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: afee00a5-601b-4dc5-a654-c9bb173df045\n",
      "Query executing: 0.00s\n",
      "Query complete after 0.34s\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    CREATE OR REPLACE VIEW `{BQ_DATASET_NAME}.vw_item_groups`\n",
    "    AS\n",
    "    SELECT\n",
    "      list_Id AS group_Id,\n",
    "      track_Id AS item_Id\n",
    "    FROM  \n",
    "      `{BQ_DATASET_NAME}.playlist` \n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "query_job = wait_for_result(query_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute item co-occurence\n",
    "\n",
    "You will now compute item co-occurence.\n",
    "\n",
    "#### Create the stored procedure that encapsulates calculation logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: c8d94122-64a6-4b5e-b1a9-3a736eefca13\n",
      "Query executing: 0.55s\n",
      "Query complete after 1.14s\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    CREATE OR REPLACE PROCEDURE {BQ_DATASET_NAME}.sp_ComputePMI(\n",
    "    IN min_item_frequency INT64,\n",
    "    IN max_group_size INT64\n",
    "    )\n",
    "\n",
    "    BEGIN\n",
    "\n",
    "    DECLARE total INT64;\n",
    "\n",
    "    # Get items with minimum frequency\n",
    "    CREATE OR REPLACE TABLE {BQ_DATASET_NAME}.valid_item_groups\n",
    "    AS\n",
    "\n",
    "    # Create valid item set\n",
    "    WITH \n",
    "    valid_items AS (\n",
    "        SELECT item_Id, COUNT(group_Id) AS item_frequency\n",
    "        FROM {BQ_DATASET_NAME}.vw_item_groups\n",
    "        GROUP BY item_Id\n",
    "        HAVING item_frequency >= min_item_frequency\n",
    "    ),\n",
    "\n",
    "    # Create valid group set\n",
    "    valid_groups AS (\n",
    "        SELECT group_Id, COUNT(item_Id) AS group_size\n",
    "        FROM {BQ_DATASET_NAME}.vw_item_groups\n",
    "        WHERE item_Id IN (SELECT item_Id FROM valid_items)\n",
    "        GROUP BY group_Id\n",
    "        HAVING group_size BETWEEN 2 AND max_group_size\n",
    "    )\n",
    "\n",
    "    SELECT item_Id, group_Id\n",
    "    FROM {BQ_DATASET_NAME}.vw_item_groups\n",
    "    WHERE item_Id IN (SELECT item_Id FROM valid_items)\n",
    "    AND group_Id IN (SELECT group_Id FROM valid_groups);\n",
    "\n",
    "    # Compute pairwise cooc\n",
    "    CREATE OR REPLACE TABLE {BQ_DATASET_NAME}.item_cooc\n",
    "    AS\n",
    "    SELECT item1_Id, item2_Id, SUM(cooc) AS cooc\n",
    "    FROM\n",
    "    (\n",
    "        SELECT\n",
    "        a.item_Id item1_Id,\n",
    "        b.item_Id item2_Id,\n",
    "        1 as cooc\n",
    "        FROM {BQ_DATASET_NAME}.valid_item_groups a\n",
    "        JOIN {BQ_DATASET_NAME}.valid_item_groups b\n",
    "        ON a.group_Id = b.group_Id\n",
    "        AND a.item_Id < b.item_Id\n",
    "    )\n",
    "    GROUP BY  item1_Id, item2_Id;\n",
    "\n",
    "    ###################################\n",
    "    \n",
    "    # Compute item frequencies\n",
    "    CREATE OR REPLACE TABLE {BQ_DATASET_NAME}.item_frequency\n",
    "    AS\n",
    "    SELECT item_Id, COUNT(group_Id) AS frequency\n",
    "    FROM {BQ_DATASET_NAME}.valid_item_groups\n",
    "    GROUP BY item_Id;\n",
    "\n",
    "    ###################################\n",
    "    \n",
    "    # Compute total frequency |D|\n",
    "    SET total = (\n",
    "        SELECT SUM(frequency)  AS total\n",
    "        FROM {BQ_DATASET_NAME}.item_frequency\n",
    "    );\n",
    "    \n",
    "    ###################################\n",
    "    \n",
    "    # Add mirror item-pair cooc and same item frequency as cooc\n",
    "    CREATE OR REPLACE TABLE {BQ_DATASET_NAME}.item_cooc\n",
    "    AS\n",
    "    SELECT item1_Id, item2_Id, cooc\n",
    "    FROM {BQ_DATASET_NAME}.item_cooc\n",
    "    UNION ALL\n",
    "    SELECT item2_Id as item1_Id, item1_Id AS item2_Id, cooc\n",
    "    FROM {BQ_DATASET_NAME}.item_cooc\n",
    "    UNION ALL\n",
    "    SELECT item_Id as item1_Id, item_Id AS item2_Id, frequency as cooc\n",
    "    FROM {BQ_DATASET_NAME}.item_frequency;\n",
    "\n",
    "    ###################################\n",
    "    \n",
    "    # Compute PMI\n",
    "    CREATE OR REPLACE TABLE {BQ_DATASET_NAME}.item_cooc\n",
    "    AS\n",
    "    SELECT\n",
    "        a.item1_Id,\n",
    "        a.item2_Id,\n",
    "        a.cooc,\n",
    "        LOG(a.cooc, 2) - LOG(b.frequency, 2) - LOG(c.frequency, 2) + LOG(total, 2) AS pmi\n",
    "    FROM {BQ_DATASET_NAME}.item_cooc a\n",
    "    JOIN {BQ_DATASET_NAME}.item_frequency b\n",
    "    ON a.item1_Id = b.item_Id\n",
    "    JOIN {BQ_DATASET_NAME}.item_frequency c\n",
    "    ON a.item2_Id = c.item_Id; \n",
    "    END\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "query_job = wait_for_result(query_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute the stored procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: 1928be93-cb79-42e8-9c01-a0f69abc80b5\n",
      "Query executing: 151.43s\n",
      "Query complete after 151.99s\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    DECLARE min_item_frequency INT64;\n",
    "    DECLARE max_group_size INT64;\n",
    "\n",
    "    SET min_item_frequency = 15;\n",
    "    SET max_group_size = 100;\n",
    "\n",
    "    CALL {BQ_DATASET_NAME}.sp_ComputePMI(min_item_frequency, max_group_size);\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "query_job = wait_for_result(query_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the co-occurence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item1_Id</th>\n",
       "      <th>item2_Id</th>\n",
       "      <th>freq1</th>\n",
       "      <th>freq2</th>\n",
       "      <th>cooc</th>\n",
       "      <th>pmi</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>721785</td>\n",
       "      <td>790948</td>\n",
       "      <td>1003</td>\n",
       "      <td>927</td>\n",
       "      <td>182</td>\n",
       "      <td>8.602703</td>\n",
       "      <td>1565.691987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>790948</td>\n",
       "      <td>721785</td>\n",
       "      <td>927</td>\n",
       "      <td>1003</td>\n",
       "      <td>182</td>\n",
       "      <td>8.602703</td>\n",
       "      <td>1565.691987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>907016</td>\n",
       "      <td>907020</td>\n",
       "      <td>1159</td>\n",
       "      <td>1666</td>\n",
       "      <td>192</td>\n",
       "      <td>7.625565</td>\n",
       "      <td>1464.108474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>907020</td>\n",
       "      <td>907016</td>\n",
       "      <td>1666</td>\n",
       "      <td>1159</td>\n",
       "      <td>192</td>\n",
       "      <td>7.625565</td>\n",
       "      <td>1464.108474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>677232</td>\n",
       "      <td>676183</td>\n",
       "      <td>1313</td>\n",
       "      <td>1094</td>\n",
       "      <td>172</td>\n",
       "      <td>7.893657</td>\n",
       "      <td>1357.708924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>676183</td>\n",
       "      <td>677232</td>\n",
       "      <td>1094</td>\n",
       "      <td>1313</td>\n",
       "      <td>172</td>\n",
       "      <td>7.893657</td>\n",
       "      <td>1357.708924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1581670</td>\n",
       "      <td>1581664</td>\n",
       "      <td>1025</td>\n",
       "      <td>818</td>\n",
       "      <td>144</td>\n",
       "      <td>8.414000</td>\n",
       "      <td>1211.615968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1581664</td>\n",
       "      <td>1581670</td>\n",
       "      <td>818</td>\n",
       "      <td>1025</td>\n",
       "      <td>144</td>\n",
       "      <td>8.414000</td>\n",
       "      <td>1211.615968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>908984</td>\n",
       "      <td>955246</td>\n",
       "      <td>1348</td>\n",
       "      <td>1453</td>\n",
       "      <td>161</td>\n",
       "      <td>7.350933</td>\n",
       "      <td>1183.500231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>955246</td>\n",
       "      <td>908984</td>\n",
       "      <td>1453</td>\n",
       "      <td>1348</td>\n",
       "      <td>161</td>\n",
       "      <td>7.350933</td>\n",
       "      <td>1183.500231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item1_Id  item2_Id  freq1  freq2  cooc       pmi        score\n",
       "0    721785    790948   1003    927   182  8.602703  1565.691987\n",
       "1    790948    721785    927   1003   182  8.602703  1565.691987\n",
       "2    907016    907020   1159   1666   192  7.625565  1464.108474\n",
       "3    907020    907016   1666   1159   192  7.625565  1464.108474\n",
       "4    677232    676183   1313   1094   172  7.893657  1357.708924\n",
       "5    676183    677232   1094   1313   172  7.893657  1357.708924\n",
       "6   1581670   1581664   1025    818   144  8.414000  1211.615968\n",
       "7   1581664   1581670    818   1025   144  8.414000  1211.615968\n",
       "8    908984    955246   1348   1453   161  7.350933  1183.500231\n",
       "9    955246    908984   1453   1348   161  7.350933  1183.500231"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    SELECT \n",
    "        a.item1_Id, \n",
    "        a.item2_Id, \n",
    "        b.frequency AS freq1,\n",
    "        c.frequency AS freq2,\n",
    "        a.cooc,\n",
    "        a.pmi,\n",
    "        a.cooc * a.pmi AS score\n",
    "    FROM {BQ_DATASET_NAME}.item_cooc a\n",
    "    JOIN {BQ_DATASET_NAME}.item_frequency b\n",
    "    ON a.item1_Id = b.item_Id\n",
    "    JOIN {BQ_DATASET_NAME}.item_frequency c \n",
    "    ON a.item2_Id = c.item_Id\n",
    "    WHERE a.item1_Id != a.item2_Id\n",
    "    ORDER BY score DESC\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Matrix Factorization Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a stored procedure that encapsulates the training statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: fd874318-327b-4e8f-a12f-d45c6daa101f\n",
      "Query executing: 0.54s\n",
      "Query complete after 1.11s\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    CREATE OR REPLACE PROCEDURE {BQ_DATASET_NAME}.sp_TrainItemMatchingModel(\n",
    "        IN dimensions INT64\n",
    "    )\n",
    "\n",
    "    BEGIN\n",
    "\n",
    "    CREATE OR REPLACE MODEL {BQ_DATASET_NAME}.item_matching_model\n",
    "    OPTIONS(\n",
    "        MODEL_TYPE='matrix_factorization', \n",
    "        FEEDBACK_TYPE='implicit',\n",
    "        WALS_ALPHA=1,\n",
    "        NUM_FACTORS=(dimensions),\n",
    "        USER_COL='item1_Id', \n",
    "        ITEM_COL='item2_Id',\n",
    "        RATING_COL='score',\n",
    "        DATA_SPLIT_METHOD='no_split'\n",
    "    )\n",
    "    AS\n",
    "    SELECT \n",
    "        item1_Id, \n",
    "        item2_Id, \n",
    "        cooc * pmi AS score\n",
    "    FROM {BQ_DATASET_NAME}.item_cooc;\n",
    "    END\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "query_job = wait_for_result(query_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training\n",
    "\n",
    "Be patient - training can take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: 18e6f6b6-2bba-4a88-8b32-8d54d0c01846\n",
      "Query executing: 7260.71s\n",
      "Query complete after 7260.78s\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    DECLARE dimensions INT64 DEFAULT 50;\n",
    "    CALL {BQ_DATASET_NAME}.sp_TrainItemMatchingModel(dimensions)\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "query_job = wait_for_result(query_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the trained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a stored procedure that extracts embeddings from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: 6d1c238e-120b-4664-8422-e450d2d14883\n",
      "Query executing: 0.57s\n",
      "Query complete after 1.20s\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    CREATE OR REPLACE PROCEDURE {BQ_DATASET_NAME}.sp_ExractEmbeddings() \n",
    "    BEGIN\n",
    "    CREATE OR REPLACE TABLE {BQ_DATASET_NAME}.item_embeddings AS\n",
    "        WITH \n",
    "        step1 AS\n",
    "        (\n",
    "            SELECT \n",
    "                feature AS item_Id,\n",
    "                factor_weights\n",
    "            FROM\n",
    "                ML.WEIGHTS(MODEL `{BQ_DATASET_NAME}..item_matching_model`)\n",
    "            WHERE feature != 'global__INTERCEPT__'\n",
    "        ),\n",
    "\n",
    "        step2 AS\n",
    "        (\n",
    "            SELECT \n",
    "                item_Id, \n",
    "                factor, \n",
    "                SUM(weight) AS weight\n",
    "            FROM step1,\n",
    "            UNNEST(step1.factor_weights) AS embedding\n",
    "            GROUP BY \n",
    "            item_Id,\n",
    "            factor \n",
    "        )\n",
    "\n",
    "        SELECT \n",
    "            item_Id as id, \n",
    "            ARRAY_AGG(weight ORDER BY factor ASC) embedding,\n",
    "        FROM step2\n",
    "        GROUP BY item_Id;\n",
    "    END \n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "query_job = wait_for_result(query_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract embeddings to a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: 97e3d9e7-02ac-4ffb-ba29-70f398324aaf\n",
      "Query executing: 7.34s\n",
      "Query complete after 7.90s\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "CALL {BQ_DATASET_NAME}.sp_ExractEmbeddings()\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "query_job = wait_for_result(query_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify the number of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   embedding_count\n",
       "0             5000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    SELECT COUNT(*) embedding_count\n",
    "    FROM {BQ_DATASET_NAME}.item_embeddings;\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export embeddings to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: a38a263e-9ea6-400a-805c-81afadc6d551\n",
      "Query executing: 10.04s\n",
      "Query complete after 10.60s\n"
     ]
    }
   ],
   "source": [
    "file_name_pattern = 'embedding-*.json'\n",
    "destination_uri = f'gs://{BUCKET_NAME}/embeddings/{file_name_pattern}'\n",
    "table_id = 'item_embeddings'\n",
    "location = BQ_LOCATION\n",
    "destination_format = 'NEWLINE_DELIMITED_JSON'\n",
    "\n",
    "client = bigquery.Client()\n",
    "dataset_ref = bigquery.DatasetReference(PROJECT_ID, BQ_DATASET_NAME)\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "job_config = bigquery.job.ExtractJobConfig()\n",
    "job_config.destination_format = bigquery.DestinationFormat.NEWLINE_DELIMITED_JSON\n",
    "\n",
    "extract_job = client.extract_table(\n",
    "    table_ref,\n",
    "    destination_uris=destination_uri,\n",
    "    job_config=job_config,\n",
    "    location=location,\n",
    ")  # API request\n",
    "\n",
    "extract_job = wait_for_result(extract_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "Copyright 2020 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License. You may obtain a copy of the License at: http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
    "\n",
    "See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "**This is not an official Google product but sample code provided for an educational purpose**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

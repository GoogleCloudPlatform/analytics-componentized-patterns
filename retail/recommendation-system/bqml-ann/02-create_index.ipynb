{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-latency item-to-item recommendation system \n",
    "\n",
    "## Part 1 - Creating ANN index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook is a part of the [**Low-latency item-to-item recommendation system** ML Engineering blueprint](https://github.com/jarokaz/analytics-componentized-patterns/tree/master/retail/recommendation-system/bqml-ann).\n",
    "\n",
    "The blueprint provides guidance and code samples for how to develop and operationalize a near real-time item-to-itme recommendations system that utilizes BigQuery, BigQuery ML and AI Platform ANN Service.\n",
    "\n",
    "This notebook demonstrates how to create and deploy an ANN index using embeddings exported in Part 1 - Creating embeddings. In the notebook you go through the following steps.\n",
    "\n",
    "1. Creating an ANN Index using the embeddings data in the JSONL format.\n",
    "2. Creating and ANN Endpoint. \n",
    "3. Deploying the ANN Index to the ANN Endpoint.\n",
    "\n",
    "This notebook was designed to run on [AI Platform Notebooks](https://cloud.google.com/ai-platform/notebooks/docs) using the standard TensorFlow 2.3 image. Your notebook instance should be in the same project as the AI Platform ANN Service.\n",
    "\n",
    "While AI Platform ANN Service is in the Experimental stage your project must be allow-listed before using the service. Contact `gcp-ann-feedback@` to allow list your project and user id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the notebook's environment\n",
    "\n",
    "### Configuring AI Platform ANN Service\n",
    "\n",
    "#### Enable the required Cloud APIs\n",
    "\n",
    "You need to enable the following APIs to use the ANN service:\n",
    "* aiplatform.googleapis.com\n",
    "* servicenetworking.googleapis.com\n",
    "* compute.googleapis.com\n",
    "\n",
    "#### Prepare a VPC network\n",
    "\n",
    "In the experimental release, ANN service is only accessible using private endpoints. Before using the service you need to have a [VPC network](https://cloud.google.com/vpc) configured with [private services access](https://cloud.google.com/vpc/docs/configure-private-services-access). You can use the `default` VPC or create a new one.\n",
    "\n",
    "The below instructions are for a VPC that was created with auto subnets and regional dynamic routing mode (defaults). It is recommended that you execute the below commands from Cloud Shell, using the account with appropriate permissions - `roles/compute.networkAdmin`.\n",
    "\n",
    "1. Set environment variables for your project ID, the name of your VPC network, and the name of your reserved range of addresses. The name of the reserved range can be an arbitrary name. It is for display only.\n",
    "\n",
    "```\n",
    "PROJECT_ID=<your-project-id>\n",
    "gcloud config set project $PROJECT_ID\n",
    "NETWORK_NAME=<your-VPC-network-name>\n",
    "PEERING_RANGE_NAME=google-reserved-range\n",
    "\n",
    "```\n",
    "\n",
    "2. Reserve an IP range for Google services. The reserved range should be large enought to accommodate all peered services. The below command reserves a CIDR block with mask /16\n",
    "\n",
    "```\n",
    "gcloud compute addresses create $PEERING_RANGE_NAME \\\n",
    "  --global \\\n",
    "  --prefix-length=16 \\\n",
    "  --description=\"peering range for Google service: AI Platform Online Prediction\" \\\n",
    "  --network=$NETWORK_NAME \\\n",
    "  --purpose=VPC_PEERING \\\n",
    "  --project=$PROJECT_ID\n",
    "\n",
    "```\n",
    "\n",
    "3. Create a private connection to establish a VPC Network Peering between your VPC network and the Google services network.\n",
    "\n",
    "```\n",
    "gcloud services vpc-peerings connect \\\n",
    "  --service=servicenetworking.googleapis.com \\\n",
    "  --network=$NETWORK_NAME \\\n",
    "  --ranges=$PEERING_RANGE_NAME \\\n",
    "  --project=$PROJECT_ID\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing notebook dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import grpc\n",
    "import match_pb2\n",
    "import match_pb2_grpc\n",
    "\n",
    "import google.auth\n",
    "import numpy as np\n",
    "import tensorflow.io as tf_io\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from typing import List, Optional, Text, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure GCP environment\n",
    "\n",
    "Set the following constants to the values reflecting your environment:\n",
    "\n",
    "* `PROJECT_ID` - your GCP project ID\n",
    "* `PROJECT_NUMBER` - your GCP project number\n",
    "* `DATA_LOCATION` - a GCS location of the embeddings (JSONL) files exported in Part 1\n",
    "* `VPC_NAME` - a name of the GCP VPC to use for the index deployments. Use the name of the VPC prepared in the previous section. \n",
    "* `REGION` - a compute region. Don't change the default - `us-central` - while the ANN Service is in the experimental stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jk-mlops-dev'\n",
    "PROJECT_NUMBER = '895222332033'\n",
    "DATA_LOCATION = 'gs://jk-ann-staging/embeddings' \n",
    "REGION = 'us-central1'\n",
    "VPC_NAME = 'default'\n",
    "\n",
    "MATCH_SERVICE_PORT = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an ANN index deployment\n",
    "\n",
    "You will use the REST interface to invoke the AI Platform ANN Service control plane APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper classes to encapsulate the ANN Service REST API.\n",
    "\n",
    "Currently, there is no Python client that encapsulates the ANN Service API. The below code snippet defines a simple wrapper that encapsulates a subset of REST APIs used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNClient(object):\n",
    "    \"\"\"Base ANN Service client.\"\"\"\n",
    "    \n",
    "    def __init__(self, project_id, project_number, region):\n",
    "        credentials, _ = google.auth.default()\n",
    "        self.authed_session = google.auth.transport.requests.AuthorizedSession(credentials)\n",
    "        self.ann_endpoint = f'{region}-aiplatform.googleapis.com'\n",
    "        self.ann_parent = f'https://{self.ann_endpoint}/v1alpha1/projects/{project_id}/locations/{region}'\n",
    "        self.project_id = project_id\n",
    "        self.project_number = project_number\n",
    "        self.region = region\n",
    "        \n",
    "    def wait_for_completion(self, operation_id, message, sleep_time):\n",
    "        \"\"\"Waits for a completion of a long running operation.\"\"\"\n",
    "        \n",
    "        api_url = f'{self.ann_parent}/operations/{operation_id}'\n",
    "\n",
    "        start_time = datetime.datetime.utcnow()\n",
    "        while True:\n",
    "            response = self.authed_session.get(api_url)\n",
    "            if 'done' in response.json().keys():\n",
    "                logging.info('Operation completed!')\n",
    "                break\n",
    "            elapsed_time = datetime.datetime.utcnow() - start_time\n",
    "            logging.info('{}. Elapsed time since start: {}.'.format(\n",
    "                message, str(elapsed_time)))\n",
    "            time.sleep(sleep_time)\n",
    "            \n",
    "            print(response)\n",
    "    \n",
    "        return response.json()['response']\n",
    "\n",
    "\n",
    "class IndexClient(ANNClient):\n",
    "    \"\"\"Encapsulates a subset of control plane APIs \n",
    "    that manage ANN indexes.\"\"\"\n",
    "\n",
    "    def __init__(self, project_id, project_number, region):\n",
    "        super().__init__(project_id, project_number, region)\n",
    "\n",
    "    def create_index(self, display_name, description, metadata):\n",
    "        \"\"\"Creates an ANN Index.\"\"\"\n",
    "    \n",
    "        api_url = f'{self.ann_parent}/indexes'\n",
    "    \n",
    "        request_body = {\n",
    "            'display_name': display_name,\n",
    "            'description': description,\n",
    "            'metadata': metadata\n",
    "        }\n",
    "    \n",
    "        response = self.authed_session.post(api_url, data=json.dumps(request_body))\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "        operation_id = response.json()['name'].split('/')[-1]\n",
    "        \n",
    "        return operation_id\n",
    "\n",
    "    def list_indexes(self, display_name=None):\n",
    "        \"\"\"Lists all indexes with a given display name or\n",
    "        all indexes if the display_name is not provided.\"\"\"\n",
    "    \n",
    "        if display_name:\n",
    "            api_url = f'{self.ann_parent}/indexes?filter=display_name=\"{display_name}\"'\n",
    "        else:\n",
    "            api_url = f'{self.ann_parent}/indexes'\n",
    "\n",
    "        response = self.authed_session.get(api_url).json()\n",
    "\n",
    "        return response['indexes'] if response else []\n",
    "    \n",
    "    def delete_index(self, index_id):\n",
    "        \"\"\"Deletes an ANN index.\"\"\"\n",
    "        \n",
    "        api_url = f'{self.ann_parent}/indexes/{index_id}'\n",
    "        response = self.authed_session.delete(api_url)\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "\n",
    "\n",
    "class IndexDeploymentClient(ANNClient):\n",
    "    \"\"\"Encapsulates a subset of control plane APIs \n",
    "    that manage ANN endpoints and deployments.\"\"\"\n",
    "    \n",
    "    def __init__(self, project_id, project_number, region):\n",
    "        super().__init__(project_id, project_number, region)\n",
    "\n",
    "    def create_endpoint(self, display_name, vpc_name):\n",
    "        \"\"\"Creates an ANN endpoint.\"\"\"\n",
    "    \n",
    "        api_url = f'{self.ann_parent}/indexEndpoints'\n",
    "        network_name = f'projects/{self.project_number}/global/networks/{vpc_name}'\n",
    "\n",
    "        request_body = {\n",
    "            'display_name': display_name,\n",
    "            'network': network_name\n",
    "        }\n",
    "\n",
    "        response = self.authed_session.post(api_url, data=json.dumps(request_body))\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "        operation_id = response.json()['name'].split('/')[-1]\n",
    "    \n",
    "        return operation_id\n",
    "    \n",
    "    def list_endpoints(self, display_name=None):\n",
    "        \"\"\"Lists all ANN endpoints with a given display name or\n",
    "        all endpoints in the project if the display_name is not provided.\"\"\"\n",
    "        \n",
    "        if display_name:\n",
    "            api_url = f'{self.ann_parent}/indexEndpoints?filter=display_name=\"{display_name}\"'\n",
    "        else:\n",
    "            api_url = f'{self.ann_parent}/indexEndpoints'\n",
    "\n",
    "        response = self.authed_session.get(api_url).json()\n",
    " \n",
    "        return response['indexEndpoints'] if response else []\n",
    "    \n",
    "    def delete_endpoint(self, endpoint_id):\n",
    "        \"\"\"Deletes an ANN endpoint.\"\"\"\n",
    "        \n",
    "        api_url = f'{self.ann_parent}/indexEndpoints/{endpoint_id}'\n",
    "        \n",
    "        response = self.authed_session.delete(api_url)\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "        \n",
    "        return response.json()\n",
    "    \n",
    "    def create_deployment(self, display_name, deployment_id, endpoint_id, index_id):\n",
    "        \"\"\"Deploys an ANN index to an endpoint.\"\"\"\n",
    "    \n",
    "        api_url = f'{self.ann_parent}/indexEndpoints/{endpoint_id}:deployIndex'\n",
    "        index_name = f'projects/{self.project_number}/locations/{self.region}/indexes/{index_id}'\n",
    "\n",
    "        request_body = {\n",
    "            'deployed_index': {\n",
    "                'id': deployment_id,\n",
    "                'index': index_name,\n",
    "                'display_name': display_name\n",
    "            }\n",
    "        }\n",
    "\n",
    "        response = self.authed_session.post(api_url, data=json.dumps(request_body))\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "        operation_id = response.json()['name'].split('/')[-1]\n",
    "        \n",
    "        return operation_id\n",
    "    \n",
    "    def get_deployment_grpc_ip(self, endpoint_id, deployment_id):\n",
    "        \"\"\"Returns a private IP address for a gRPC interface to \n",
    "        an Index deployment.\"\"\"\n",
    "  \n",
    "        api_url = f'{self.ann_parent}/indexEndpoints/{endpoint_id}'\n",
    "\n",
    "        response = self.authed_session.get(api_url)\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "            \n",
    "        endpoint_ip = None\n",
    "        if 'deployedIndexes' in response.json().keys():\n",
    "            for deployment in response.json()['deployedIndexes']:\n",
    "                if deployment['id'] == deployment_id:\n",
    "                    endpoint_ip = deployment['privateEndpoints']['matchGrpcAddress']\n",
    "                    \n",
    "        return endpoint_ip\n",
    "\n",
    "    \n",
    "    def delete_deployment(self, endpoint_id, deployment_id):\n",
    "        \"\"\"Undeployes an index from an endpoint.\"\"\"\n",
    "        \n",
    "        api_url = f'{self.ann_parent}/indexEndpoints/{endpoint_id}:undeployIndex'\n",
    "        \n",
    "        request_body = {\n",
    "            'deployed_index_id': deployment_id\n",
    "        }\n",
    "    \n",
    "        response = self.authed_session.post(api_url, data=json.dumps(request_body))\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    \n",
    "index_client = IndexClient(PROJECT_ID, PROJECT_NUMBER, REGION)\n",
    "deployment_client = IndexDeploymentClient(PROJECT_ID, PROJECT_NUMBER, REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_display_name = 'Song embeddings test 2'\n",
    "index_description = 'Song embeddings test 2'\n",
    "index_metadata = {\n",
    "    'contents_delta_uri': DATA_LOCATION,\n",
    "    'config': {\n",
    "        'dimensions': 50,\n",
    "        'approximate_neighbors_count': 50,\n",
    "        'distance_measure_type': 'DOT_PRODUCT_DISTANCE',\n",
    "        'feature_norm_type': 'UNIT_L2_NORM',\n",
    "        'tree_ah_config': {\n",
    "            'child_node_count': 1000,\n",
    "            'max_leaves_to_search': 100\n",
    "         }\n",
    "    }\n",
    "}\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_id = index_client.create_index(index_display_name, \n",
    "                                          index_description,\n",
    "                                          index_metadata)\n",
    "\n",
    "response = index_client.wait_for_completion(operation_id, 'Creating index', 20)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all indexes with the set display name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/895222332033/locations/us-central1/indexes/1160802803954745344\n",
      "Index: 1160802803954745344\n",
      "will be used for the deployment.\n"
     ]
    }
   ],
   "source": [
    "#indexes = index_client.list_indexes(index_display_name)\n",
    "indexes = index_client.list_indexes()\n",
    "\n",
    "for index in indexes:\n",
    "    print(index['name'])\n",
    "\n",
    "if indexes: \n",
    "    index_id = index['name'].split('/')[-1]\n",
    "    print(f'Index: {index_id}')\n",
    "    print('will be used for the deployment.')\n",
    "else:\n",
    "    print('No indexes available for deployment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the index deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an index endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_display_name = 'Song embeddings endpoint test 2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_id = deployment_client.create_endpoint(deployment_display_name, VPC_NAME)\n",
    "\n",
    "response = index_client.wait_for_completion(operation_id, 'Waiting for endpoint', 10)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No endpoints available for deployment\n"
     ]
    }
   ],
   "source": [
    "#endpoints = deployment_client.list_endpoints(deployment_display_name)\n",
    "endpoints = deployment_client.list_endpoints()\n",
    "\n",
    "for endpoint in endpoints:\n",
    "    print(endpoint)\n",
    "    print(endpoint['name'])\n",
    "    \n",
    "if endpoints: \n",
    "    endpoint_id = endpoint['name'].split('/')[-1]\n",
    "    print(f'Endpoint: {endpoint_id}')\n",
    "    print('will be used for the deployment.')\n",
    "else:\n",
    "    print('No endpoints available for deployment')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy the index to the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set the deployment ID\n",
    "\n",
    "The ID must be unique within your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_display_name = 'Songs index deployment test 2'\n",
    "deployed_index_id = 'songs_index_deployed_test_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deploy the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_id = deployment_client.create_deployment(deployment_display_name, \n",
    "                                                   deployed_index_id,\n",
    "                                                   endpoint_id,\n",
    "                                                   index_id)\n",
    "\n",
    "response = index_client.wait_for_completion(operation_id, 'Waiting for deployment', 10)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve the gRPC private endpoint for ANN Match service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_index_ip = deployment_client.get_deployment_grpc_ip(endpoint_id, deployed_index_id)\n",
    "endpoint = f'{deployed_index_ip}:{MATCH_SERVICE_PORT}'\n",
    "print(f'gRPC endpoint for the: {deployed_index_id} deployment is: {endpoint}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the ANN service\n",
    "\n",
    "You will use the gRPC interface to query the deployed index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a helper wrapper around the Match Service gRPC API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchService(object):\n",
    "    def __init__(self, endpoint, deployed_index_id):\n",
    "        self.endpoint = endpoint\n",
    "        self.deployed_index_id = deployed_index_id\n",
    "\n",
    "    def single_match(\n",
    "        self,\n",
    "        embedding: List[float],\n",
    "        num_neighbors: int) -> List[Tuple[str, float]]:\n",
    "    \n",
    "        match_request = match_pb2.MatchRequest(deployed_index_id=self.deployed_index_id,\n",
    "                                               float_val=embedding,\n",
    "                                               num_neighbors=num_neighbors)\n",
    "        with grpc.insecure_channel(endpoint) as channel:\n",
    "            stub = match_pb2_grpc.MatchServiceStub(channel)\n",
    "            response = stub.Match(match_request)\n",
    "    \n",
    "        return [(neighbor.id, neighbor.distance) for neighbor in response.neighbor]\n",
    "\n",
    "\n",
    "    def batch_match(\n",
    "        self,\n",
    "        embeddings: List[List[float]],\n",
    "        num_neighbors: int) -> List[List[Tuple[str, float]]]:\n",
    "    \n",
    "        match_requests = [\n",
    "            match_pb2.MatchRequest(deployed_index_id=self.deployed_index_id,\n",
    "                                   float_val=embedding,\n",
    "                                   num_neighbors=num_neighbors)\n",
    "            for embedding in embeddings]\n",
    "    \n",
    "        batches_per_index = [\n",
    "            match_pb2.BatchMatchRequest.BatchMatchRequestPerIndex(\n",
    "                deployed_index_id=self.deployed_index_id,\n",
    "                requests=match_requests)]\n",
    "    \n",
    "        batch_match_request = match_pb2.BatchMatchRequest(\n",
    "            requests=batches_per_index)\n",
    "    \n",
    "        with grpc.insecure_channel(endpoint) as channel:\n",
    "            stub = match_pb2_grpc.MatchServiceStub(channel)\n",
    "            response = stub.BatchMatch(batch_match_request)\n",
    "        \n",
    "        matches = []\n",
    "        for batch_per_index in response.responses:\n",
    "            for match in batch_per_index.responses:\n",
    "                matches.append(\n",
    "                    [(neighbor.id, neighbor.distance) for neighbor in match.neighbor])\n",
    "        \n",
    "        return matches\n",
    "    \n",
    "match_service = MatchService(endpoint, deployed_index_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery df_embeddings\n",
    "\n",
    "SELECT id, embedding\n",
    "FROM `recommendations.item_embeddings` \n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_embeddings = [list(embedding) for embedding in df_embeddings.iloc[0:2]['embedding']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a single match query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_match = match_service.single_match(sample_embeddings[0], 10)\n",
    "single_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a batch match query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_match = match_service.batch_match(sample_embeddings, 5)\n",
    "batch_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "**WARNING**\n",
    "\n",
    "The below code will delete all ANN deployments, endpoints, and indexes in the configured project.\n",
    "\n",
    "### Delete index deployments and endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting endpoint: projects/895222332033/locations/us-central1/indexEndpoints/4009329568266584064\n",
      "Deleting endpoint: projects/895222332033/locations/us-central1/indexEndpoints/2270940112101572608\n",
      "Deleting endpoint: projects/895222332033/locations/us-central1/indexEndpoints/6315172577480278016\n",
      "Deleting endpoint: projects/895222332033/locations/us-central1/indexEndpoints/1703486559052890112\n"
     ]
    }
   ],
   "source": [
    "for endpoint in deployment_client.list_endpoints():\n",
    "    endpoint_id = endpoint['name'].split('/')[-1]\n",
    "    if 'deployedIndexes' in endpoint.keys():\n",
    "        for deployment in endpoint['deployedIndexes']:\n",
    "            print('   Deleting index deployment: {} in the endpoint: {} '.format(deployment['id'], endpoint_id))\n",
    "            deployment_client.delete_deployment(endpoint_id, deployment['id'])\n",
    "    print('Deleting endpoint: {}'.format(endpoint['name']))\n",
    "    deployment_client.delete_endpoint(endpoint_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete indexes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for index in index_client.list_indexes():\n",
    "    index_id = index['name'].split('/')[-1]\n",
    "    print('Deleting index: {}'.format(index['name']))\n",
    "    index_client.delete_index(index_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "Copyright 2020 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License. You may obtain a copy of the License at: http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
    "\n",
    "See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "**This is not an official Google product but sample code provided for an educational purpose**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

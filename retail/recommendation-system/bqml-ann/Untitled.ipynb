{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-latency item-to-item recommendation system \n",
    "\n",
    "## Part 4 - Analyzing pipeline runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.python.keras import layers, Sequential\n",
    "from tensorflow.python.keras.utils import data_utils\n",
    "from google.cloud import aiplatform\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.connect(project='jk-mlops-dev', location='us-central1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = aiplatform.stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-97844502d995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mstore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstores\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not iterable"
     ]
    }
   ],
   "source": [
    "for store in stores:\n",
    "    print(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Any',\n",
       " 'Callable',\n",
       " 'ContextManager',\n",
       " 'Generator',\n",
       " 'Optional',\n",
       " 'T',\n",
       " 'TypeVar',\n",
       " 'Union',\n",
       " '__annotations__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_assert_client_is_connected',\n",
       " '_client',\n",
       " '_reset',\n",
       " 'clients',\n",
       " 'connect',\n",
       " 'execution',\n",
       " 'experiment',\n",
       " 'functools',\n",
       " 'get_artifact',\n",
       " 'get_current_execution',\n",
       " 'get_current_experiment',\n",
       " 'get_dataset',\n",
       " 'get_experiments_dataframe',\n",
       " 'get_model',\n",
       " 'graph_experiment',\n",
       " 'importlib',\n",
       " 'log_artifact',\n",
       " 'log_dataset',\n",
       " 'log_metric',\n",
       " 'log_metrics',\n",
       " 'log_model',\n",
       " 'log_parameter',\n",
       " 'log_parameters',\n",
       " 'pd',\n",
       " 'set_experiment',\n",
       " 'stores',\n",
       " 'sys',\n",
       " 'types',\n",
       " 'utils']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(aiplatform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package google.cloud.aiplatform in google.cloud:\n",
      "\n",
      "NAME\n",
      "    google.cloud.aiplatform - SDK APIs for Experiment tracking using Cloud ML Metadata.\n",
      "\n",
      "DESCRIPTION\n",
      "    Below is the singleton client implementation to expose ML Metadata\n",
      "    logging at the root module level. Usage pattern:\n",
      "    \n",
      "    from google.cloud import aiplatform\n",
      "    \n",
      "    aiplatform.connect(project='my-project', location='us-central1')\n",
      "    \n",
      "    aiplatform.set_experiment('my_experiment')\n",
      "    aiplatform.log_dataset(my_dataset, name='my_dataset')\n",
      "    \n",
      "    with aiplatform.experiment('my_training_experiment'):\n",
      "      aiplatform.log_parameter(key='learning_rate', value=0.01)\n",
      "      aiplatform.log_model(model, name='my_model')\n",
      "      aiplatform.log_metric(key='accuracy', value=my_accuracy)\n",
      "    \n",
      "    aiplatform.connect must be called to connect to store before invoking other\n",
      "    logging methods.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    aiplatform_test\n",
      "    clients\n",
      "    clients_test\n",
      "    gapic (package)\n",
      "    stores\n",
      "    stores_test\n",
      "    types (package)\n",
      "    utils (package)\n",
      "\n",
      "FUNCTIONS\n",
      "    connect(metadata_store_resource_name: Union[str, NoneType] = None, *, project: Union[str, NoneType] = None, location: Union[str, NoneType] = 'us-central1', store_name: Union[str, NoneType] = 'default')\n",
      "        Connects to a metadata store.\n",
      "        \n",
      "        aiplatform.connect('projects/my-project/location/us-central1/metadataStores/my-store')\n",
      "        If metadata_store_resource_name is set in config, that store must exist and\n",
      "        will be used.\n",
      "        \n",
      "        \n",
      "        aiplatform.connect(project='my-project', location='us-central1')\n",
      "        If only project and location are set in config, 'default' store will be\n",
      "        used. If 'default' store doesn't exist it will be created.\n",
      "        \n",
      "        aiplatform.connect(project='my-project', location='us-central1',\n",
      "                         store='my-store')\n",
      "        If project, location, and store_name are set in config, that store will be\n",
      "        used. If it doesn't exist it will be created.\n",
      "        \n",
      "        aiplatform.connect()\n",
      "        If none of the args are provided a temporary local in-memory MLMD store will\n",
      "        be used.\n",
      "        \n",
      "        Args:\n",
      "          metadata_store_resource_name: fully qualified metadata resource name\n",
      "          project: GCP project name or id\n",
      "          location: GCP region for metadata store\n",
      "          store_name: name of the metadata store\n",
      "    \n",
      "    execution(name: Union[str, NoneType] = None, description: Union[str, NoneType] = None) -> Callable[[Callable[..., ~T]], ~T]\n",
      "        Execution decorator used to decorate and capture methods as Executions.\n",
      "        \n",
      "        When the decorated method is invoked the Execution will be captured. Input\n",
      "        arguments will be captured in input Artifacts to the Execution if that\n",
      "        Artifact has been logged by aiplatform. Artifacts logged in the method will\n",
      "        be captured as outputs to that Execution.\n",
      "        \n",
      "        Usage:\n",
      "        \n",
      "        @aiplatform.execution(name='Trainer')\n",
      "        def my_train_method(X, Y):\n",
      "          model = train_model(X, y)\n",
      "          model.log_model(model, 'my_model')\n",
      "          return model\n",
      "        \n",
      "        X, Y = get_data()\n",
      "        model = my_train_model(X, Y)\n",
      "        \n",
      "        Args:\n",
      "          name(Optional): The descriptive name for this Execution.\n",
      "          description(Optional): A short text description of the purpose of this\n",
      "            execution.\n",
      "        \n",
      "        Returns:\n",
      "          Wrapped method that captures Execution metadata and invokes method.\n",
      "        Raises:\n",
      "          Any Exception raised by the invoked method.\n",
      "    \n",
      "    experiment(name: str) -> AbstractContextManager[google.cloud.aiplatform.clients.AiPlatformMetadataClient]\n",
      "        Sets the experiment using a context manager.\n",
      "        \n",
      "        Sets the experiment with the given name using a context manager. When\n",
      "        exiting the context manager the experiment is set back to the previously set\n",
      "        experiment.\n",
      "        \n",
      "        The experiment cannot be set again until after exiting the context.\n",
      "        \n",
      "        Logging can continue against this client or against the yielded client.\n",
      "        \n",
      "        Usage:\n",
      "        \n",
      "        with aiplatform.experiment('my_experiment'):\n",
      "          aiplatform.log_metric(...)\n",
      "        \n",
      "        with aiplatform.experiment('my_experiment') as my_experiment:\n",
      "          my_experiment.log_metric(...)\n",
      "        \n",
      "        Raises Exception:\n",
      "        with aiplatform.experiment('my_experiment'):\n",
      "          with aiplatform.experiment('my_other_experiment'):\n",
      "        \n",
      "        with aiplatform.experiment('my_experiment') as my_experiment:\n",
      "          my_experiment.set_experiment('my_other_experiment')\n",
      "        \n",
      "        If an Experiment with the given name does not exist, a new\n",
      "        Experiment with that name will be created. Otherwise, the Experiment will be\n",
      "        reused.\n",
      "        \n",
      "        Args:\n",
      "          name: The name of an Experiment.\n",
      "        \n",
      "        Returns:\n",
      "          Experiment context manager\n",
      "    \n",
      "    get_artifact(artifact_id: Union[str, int], assign_as_input: bool = False) -> google.cloud.aiplatform.types.artifacts.GenericArtifact\n",
      "        Gets Generic Artifact metadata.\n",
      "        \n",
      "        After getting metadata to track the object through execution bind the object\n",
      "        instantiated with metadata.\n",
      "        \n",
      "        Example Usage:\n",
      "        \n",
      "        artifact_metadata = aiplatform.get_artifact(my_artifact_id,\n",
      "                                                    assign_as_input=True)\n",
      "        with file_io.FileIO(artifact_metadata.uri, mode='rb') as f:\n",
      "          artifact = pickle.load(f)\n",
      "        \n",
      "        artifact_metadata.bind_object(artifact)\n",
      "        \n",
      "        Args:\n",
      "          artifact_id: The id of the artifact to get. Can be a resource id or fully\n",
      "            qualified resource path.\n",
      "          assign_as_input: If True, will assign this GenericArtifact as input to the\n",
      "            current Execution.\n",
      "        Returns:\n",
      "          Generic Artifact Metadata.\n",
      "    \n",
      "    get_current_execution() -> Union[google.cloud.aiplatform.types.executions.Execution, NoneType]\n",
      "        Get the current execution in current experiment context if one exists.\n",
      "    \n",
      "    get_current_experiment() -> Union[google.cloud.aiplatform.types.contexts.ExperimentContext, NoneType]\n",
      "        Get the current Experiment for this client if one has been set.\n",
      "    \n",
      "    get_dataset(dataset_id: Union[str, int], assign_as_input: bool = False) -> google.cloud.aiplatform.types.artifacts.DatasetArtifact\n",
      "        Gets dataset metadata.\n",
      "        \n",
      "        After getting metadata to track the object through execution bind the object\n",
      "        instantiated with metadata.\n",
      "        \n",
      "        Example Usage:\n",
      "        \n",
      "        dataset_metadata = aiplatform.get_dataset(my_dataset_id, assign_as_input=True)\n",
      "        dataframe = pd.Dataframe(dataset_metadata.uri)\n",
      "        dataset_metadata.bind_object(dataset_metadata)\n",
      "        \n",
      "        Args:\n",
      "          dataset_id: The id of the dataset to get. Can be a resource id or fully\n",
      "            qualified resource path.\n",
      "          assign_as_input: If True, will assign this Dataset as input to the current\n",
      "              Execution.\n",
      "        Returns:\n",
      "          Dataset Metadata.\n",
      "    \n",
      "    get_experiments_dataframe() -> pandas.core.frame.DataFrame\n",
      "        Returns a Pandas Dataframe of all the Experiments in the store.\n",
      "        \n",
      "        Includes metrics and parameters for all the Experiments.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        client.set_experiment('exp-1')\n",
      "        client.log_parameter(key='learning_rate', value=0.1)\n",
      "        client.log_metric(key='accuracy', value=0.9)\n",
      "        \n",
      "        client.set_experiment('exp-2')\n",
      "        client.log_parameter(key='learning_rate', value=0.01)\n",
      "        client.log_metric(key='accuracy', value=0.95)\n",
      "        \n",
      "        Will result in the following DataFrame\n",
      "        ___________________________________________________________________________\n",
      "        | experiment_name | experiment_id | param.learning_rate | metric.accuracy |\n",
      "        ---------------------------------------------------------------------------\n",
      "        | exp-1           | 1             | 0.1                 | 0.9             |\n",
      "        | exp-2           | 2             | 0.01                | 0.95            |\n",
      "        ---------------------------------------------------------------------------\n",
      "        \n",
      "        The DataFrame will also contain an execution_name and execution_id field\n",
      "        to support experiments with multiple executions. Example:\n",
      "        \n",
      "        @client.execution(name='my_execution')\n",
      "        def f(key, value):\n",
      "          client.log_metric(key=key, value=value)\n",
      "        \n",
      "        client.set_experiment('exp-1')\n",
      "        \n",
      "        f('x', 0.1)\n",
      "        f('x', 0.2)\n",
      "        f('x', 0.3)\n",
      "        \n",
      "        Result in the following DataFrame (experiment_id omitted).\n",
      "        \n",
      "        ______________________________________________________________\n",
      "        | experiment_name | execution_name | execution_id | metric.x |\n",
      "        --------------------------------------------------------------\n",
      "        | exp-1           | my_execution   | 1            | 0.1      |\n",
      "        | exp-1           | my_execution   | 2            | 0.2      |\n",
      "        | exp-1           | my_execution   | 3            | 0.3      |\n",
      "        --------------------------------------------------------------\n",
      "        \n",
      "        Returns:\n",
      "          Pandas Dataframe of Experiments with metrics and parameters.\n",
      "    \n",
      "    get_model(model_id: Union[str, int], assign_as_input: bool = False) -> google.cloud.aiplatform.types.artifacts.ModelArtifact\n",
      "        Gets Model metadata.\n",
      "        \n",
      "        After getting metadata to track the object through execution bind the object\n",
      "        instantiated with metadata.\n",
      "        \n",
      "        Example Usage:\n",
      "        \n",
      "        model_metadata = aiplatform.get_model(my_model_id, assign_as_input=True)\n",
      "        model = keras.models.load_model(model_metadata.uri)\n",
      "        model_metadata.bind_object(model)\n",
      "        \n",
      "        Args:\n",
      "          model_id: The id of the model to get. Can be a resource id or fully\n",
      "            qualified resource path.\n",
      "          assign_as_input: If True, will assign this Model as input to the current\n",
      "            Execution.\n",
      "        Returns:\n",
      "          Model Metadata.\n",
      "    \n",
      "    graph_experiment(experiment_name: Union[str, NoneType] = None)\n",
      "        Visually graph the specified/current Experiment.\n",
      "        \n",
      "        Args:\n",
      "          experiment_name(Optional): The resource name of the Experiment to graph.\n",
      "            Defaults to the current Experiment.\n",
      "    \n",
      "    log_artifact(artifact: Any, name: Union[str, NoneType] = None, uri: Union[str, NoneType] = None) -> google.cloud.aiplatform.types.artifacts.GenericArtifact\n",
      "        Logs a generic Artifact to the current Execution.\n",
      "        \n",
      "        Args:\n",
      "          artifact: Any artifact object to log.\n",
      "          name (optional): The name of this artifact.\n",
      "          uri (optional): The uri for this artifact\n",
      "        \n",
      "        Returns:\n",
      "          A GenericArtifact metadata object representing this artifact.\n",
      "    \n",
      "    log_dataset(dataset: Any, name: Union[str, NoneType] = None, uri: Union[str, NoneType] = None, environment: Union[str, NoneType] = None, container_format: Union[str, NoneType] = None, payload_format: Union[str, NoneType] = None) -> google.cloud.aiplatform.types.artifacts.DatasetArtifact\n",
      "        Logs a dataset to the current Experiment.\n",
      "        \n",
      "        Args:\n",
      "          dataset: A dataset object like a pandas.DataDrame or numpy.ndarray.\n",
      "          name (Optional): The name of this Dataset, if not set, will be assigned by\n",
      "            system.\n",
      "          uri (Optional): The uri of this Dataset.\n",
      "          environment (Optional): The environment for this dataset. Examples: -\n",
      "            Training - Serving\n",
      "          container_format (Optional): Format of the container. Examples: - TFRecord -\n",
      "            Text - Parquet - NPZ\n",
      "          payload_format (Optional): Encoding format. Examples:\n",
      "                                     - proto:tf.Example - JSON - CSV\n",
      "        \n",
      "        Returns:\n",
      "          A Dataset metadata object representing the given dataset.\n",
      "    \n",
      "    log_metric(key: str, value: float) -> google.cloud.aiplatform.types.artifacts.MetricArtifact\n",
      "        Log a Metric with specified property key and value.\n",
      "        \n",
      "        Calling log_metric multiple times overwrites the value that has same key.\n",
      "        \n",
      "        Args:\n",
      "          key: Metric's property key.\n",
      "          value: Metric's property value.\n",
      "        \n",
      "        Returns:\n",
      "          Logged Metric\n",
      "    \n",
      "    log_metrics(**kwargs: float) -> google.cloud.aiplatform.types.artifacts.MetricArtifact\n",
      "        Log multiple Metrics with specified custom property key and value pairs.\n",
      "        \n",
      "        Args:\n",
      "          **kwargs: Metric's custom property key value pairs.\n",
      "        \n",
      "        Returns:\n",
      "          Logged Metric\n",
      "    \n",
      "    log_model(model: Any, name: Union[str, NoneType] = None, uri: Union[str, NoneType] = None, framework: Union[str, NoneType] = None, framework_version: Union[str, NoneType] = None) -> google.cloud.aiplatform.types.artifacts.ModelArtifact\n",
      "        Logs a model to the current Experiment.\n",
      "        \n",
      "        Args:\n",
      "          model: A ML model object like a keras.Model or sklearn Estimator.\n",
      "          name (Optional): Descriptive name of the model.\n",
      "          uri (Optional): Uri where this model is stored.\n",
      "          framework(Optional): The ML framework of the model like Tensorflow or\n",
      "            Pytorch.\n",
      "          framework_version(Optional): The version of the ML framework for the Model.\n",
      "        \n",
      "        Returns:\n",
      "          A Model metadata object representing the given model.\n",
      "    \n",
      "    log_parameter(key: str, value: Union[float, str, int])\n",
      "        Logs a single parameter to the current Execution.\n",
      "        \n",
      "        This will overwrite parameters in the Execution if given the same key.\n",
      "        \n",
      "        Args:\n",
      "          key: Parameter name.\n",
      "          value: Parameter value.\n",
      "    \n",
      "    log_parameters(**kwargs: Union[float, str, int])\n",
      "        Logs parameters to the current Execution.\n",
      "        \n",
      "        This will overwrite parameters in the Execution if given the same key.\n",
      "        \n",
      "        Args:\n",
      "          **kwargs: Parameters as key value pairs.\n",
      "    \n",
      "    set_experiment(name: str)\n",
      "        Sets the current Experiment.\n",
      "        \n",
      "        Usage:\n",
      "        \n",
      "        aiplatform.set_experiment(\"My Experiment\")\n",
      "        \n",
      "        Only one Experiment can be set at a time. The Experiment name is unique.\n",
      "        \n",
      "        If an Experiment with the given name does not exist, a new\n",
      "        Experiment with that name will be created. Otherwise, the Experiment will be\n",
      "        reused.\n",
      "        \n",
      "        Args:\n",
      "          name: The name of an Experiment.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If this method is invoked within a experiment context.\n",
      "\n",
      "DATA\n",
      "    Any = typing.Any\n",
      "    Callable = typing.Callable\n",
      "    ContextManager = typing.AbstractContextManager\n",
      "    Generator = typing.Generator\n",
      "    Optional = typing.Optional\n",
      "    T = ~T\n",
      "    Union = typing.Union\n",
      "    __annotations__ = {'_client': typing.Union[google.cloud.aiplatform.cli...\n",
      "\n",
      "FILE\n",
      "    /home/jupyter/.local/lib/python3.7/site-packages/google/cloud/aiplatform/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(aiplatform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

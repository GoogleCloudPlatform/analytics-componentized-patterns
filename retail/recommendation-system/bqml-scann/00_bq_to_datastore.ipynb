{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "00-bq-to-datastore.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAdAvk8LquRK"
      },
      "source": [
        "# Item-to-item Recommendation using Cooccurrence and Matrix Factorization (prerequisite)\n",
        "\n",
        "This tutorial shows how to use Matrix Factorization algorithm in BigQuery ML to generate embeddings for items based on their cooccurrence statistics. The generated item embeddings can be then used to find similar items.\n",
        "\n",
        "The prerequisites cover:\n",
        "\n",
        "1. Copy the `bigquery-samples dataset.playlists` public data to your dataset.\n",
        "2. Export the songs information to Datastore."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9tnKiq4q6as"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm8pqhsarF9L"
      },
      "source": [
        "!pip install -q -U apache-beam[gcp]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSNZnVZbEVO_"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMtPGiyVtZTj"
      },
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "import apache_beam as beam\n",
        "from apache_beam.io.gcp.datastore.v1new.datastoreio import WriteToDatastore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHAObQoaEfC2"
      },
      "source": [
        "### Configure GCP environment settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81apxD89q6Co"
      },
      "source": [
        "PROJECT_ID = 'ksalama-cloudml'\n",
        "BUCKET = 'ksalama-cloudml'\n",
        "DF_REGION = 'us-central1'\n",
        "\n",
        "BQ_DATASET_NAME = 'recommendations'\n",
        "BQ_TABLE_NAME = 'playlist'\n",
        "BQ_REGION = 'EU'\n",
        "DS_KIND = 'song'\n",
        "\n",
        "!gcloud config set project $PROJECT_ID"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgjoyd3CrBQi"
      },
      "source": [
        "### Authenticate your GCP account\n",
        "This is required if you run the notebook in Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU_altC3pTmd"
      },
      "source": [
        "try:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  print(\"Colab user is authenticated.\")\n",
        "except: pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XaUBOKTkzKi"
      },
      "source": [
        "## Copy the BigQuery Playlists data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBlQ3RrinurU"
      },
      "source": [
        "### Create BQ Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5OHoo3Eowfh"
      },
      "source": [
        "!bq mk --dataset --location={BQ_REGION} {PROJECT_ID}:{BQ_DATASET_NAME}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLLs69WFEqTU"
      },
      "source": [
        "### Implement data copying Beam pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSwEWeWSkzSA"
      },
      "source": [
        "def run_copy_bq_data_pipeline(args):\n",
        "\n",
        "  schema = 'list_Id:INT64, track_Id:INT64, track_title:STRING, track_artist:STRING'\n",
        "\n",
        "  query = '''\n",
        "    SELECT \n",
        "      id list_Id, \n",
        "      tracks_data_id track_Id, \n",
        "      tracks_data_title track_title,\n",
        "      tracks_data_artist_name track_artist\n",
        "    FROM `bigquery-samples.playlists.playlist`\n",
        "    WHERE tracks_data_title IS NOT NULL AND tracks_data_id > 0\n",
        "    GROUP BY list_Id, track_Id, track_title, track_artist;\n",
        "  '''\n",
        "\n",
        "  pipeline_options = beam.options.pipeline_options.PipelineOptions(**args)\n",
        "  with beam.Pipeline(options=pipeline_options) as pipeline:\n",
        "\n",
        "    _ = (\n",
        "        pipeline\n",
        "        | 'ReadFromBigQuery' >> beam.io.Read(beam.io.BigQuerySource(\n",
        "            project=PROJECT_ID, query=query, use_standard_sql=True))\n",
        "        | 'WriteToBigQuery' >> beam.io.WriteToBigQuery(\n",
        "            table=BQ_TABLE_NAME, dataset=BQ_DATASET_NAME, project=PROJECT_ID,\n",
        "            schema=schema, \n",
        "            create_disposition='CREATE_IF_NEEDED',\n",
        "            write_disposition='WRITE_TRUNCATE'\n",
        "        )\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-PAwjZmEwq8"
      },
      "source": [
        "### Run the Beam pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLvUGHUMnVDm"
      },
      "source": [
        "DATASET = 'playlist'\n",
        "RUNNER = 'Dataflow'\n",
        "\n",
        "job_name = f'copy-bigquery-{datetime.utcnow().strftime(\"%y%m%d%H%M%S\")}'\n",
        "\n",
        "args = {\n",
        "    'job_name': job_name,\n",
        "    'runner': RUNNER,\n",
        "    'project': PROJECT_ID,\n",
        "    'temp_location': f'gs://{BUCKET}/dataflow_tmp',\n",
        "    'region': DF_REGION\n",
        "}\n",
        "\n",
        "print(\"Pipeline args are set.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTpFW5HmnYtq"
      },
      "source": [
        "print(\"Running pipeline...\")\n",
        "%time run_copy_bq_data_pipeline(args)\n",
        "print(\"Pipeline is done.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO6yUMUwuxr-"
      },
      "source": [
        "### Create a view to abstract the source table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4Qya0Mtux6b"
      },
      "source": [
        "%%bigquery  --project $PROJECT_ID\n",
        "\n",
        "CREATE OR REPLACE VIEW `recommendations.vw_item_groups`\n",
        "AS\n",
        "SELECT\n",
        "  list_Id AS group_Id,\n",
        "  track_Id AS item_Id\n",
        "FROM  \n",
        "  `recommendations.playlist` "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr5mm4J3rehj"
      },
      "source": [
        "## Load the Tracks information to Datastore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvBuPJTcresj"
      },
      "source": [
        "### Implement Beam Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOANhNR3q_Tc"
      },
      "source": [
        "def create_entity(song_info, kind):\n",
        "\n",
        "  from apache_beam.io.gcp.datastore.v1new.types import Entity\n",
        "  from apache_beam.io.gcp.datastore.v1new.types import Key\n",
        "\n",
        "  track_Id = song_info.pop(\"track_Id\")\n",
        "  key = Key([kind, track_Id])\n",
        "  song_entity = Entity(key)\n",
        "  song_entity.set_properties(song_info)\n",
        "  return song_entity\n",
        "\n",
        "def run_export_to_datatore_pipeline(args):\n",
        "\n",
        "    query = f'''\n",
        "      SELECT  \n",
        "        track_Id, \n",
        "        MAX(track_title) track_title, \n",
        "        MAX(artist) artist\n",
        "      FROM \n",
        "        `{BQ_DATASET_NAME}.{BQ_TABLE_NAME}`\n",
        "      GROUP BY track_Id\n",
        "    '''\n",
        "\n",
        "    pipeline_options = beam.options.pipeline_options.PipelineOptions(**args)\n",
        "    with beam.Pipeline(options=pipeline_options) as pipeline:\n",
        "\n",
        "      _ = (\n",
        "        pipeline\n",
        "        | 'ReadFromBigQuery' >> beam.io.Read(beam.io.BigQuerySource(\n",
        "            project=PROJECT_ID, query=query, use_standard_sql=True))\n",
        "        | 'ConvertToDatastoreEntity' >> beam.Map(create_entity, DS_KIND)\n",
        "        | 'WriteToDatastore' >> WriteToDatastore(project=PROJECT_ID)\n",
        "      )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs_Fyqu7rdsU"
      },
      "source": [
        "### Run pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0zcYCsyrdzH"
      },
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "DATASET = 'playlist'\n",
        "RUNNER = 'DataflowRunner'\n",
        "\n",
        "job_name = f'load-datastore-{datetime.utcnow().strftime(\"%y%m%d%H%M%S\")}'\n",
        "\n",
        "args = {\n",
        "    'job_name': job_name,\n",
        "    'runner': RUNNER,\n",
        "    'project': PROJECT_ID,\n",
        "    'temp_location': f'gs://{BUCKET}/dataflow_tmp',\n",
        "    'region': DF_REGION\n",
        "}\n",
        "\n",
        "print(\"Pipeline args are set.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74x5kPvQsG7i"
      },
      "source": [
        "print(\"Running pipeline...\")\n",
        "%time run_export_to_datatore_pipeline(args)\n",
        "print(\"Pipeline is done.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9AGcKZRfSc-"
      },
      "source": [
        "## License\n",
        "\n",
        "Copyright 2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License. You may obtain a copy of the License at: http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
        "\n",
        "See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "**This is not an official Google product but sample code provided for an educational purpose**"
      ]
    }
  ]
}
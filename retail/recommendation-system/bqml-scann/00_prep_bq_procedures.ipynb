{"nbformat":4,"nbformat_minor":0,"metadata":{"environment":{"name":"tf2-gpu.2-3.m61","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m61"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"00_prep_bq_procedures.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"T7ya4ArX8p1h"},"source":["# Create BigQuery stored procedures\n","\n","This notebook is the second of two notebooks that guide you through completing the prerequisites for running the [Real-time Item-to-item Recommendation with BigQuery ML Matrix Factorization and ScaNN](https://github.com/GoogleCloudPlatform/analytics-componentized-patterns/tree/master/retail/recommendation-system/bqml-scann) solution.\n","\n","Use this notebook to create the following stored procedures that are needed by the solution:\n","\n","+ `sp_ComputePMI` - Computes [pointwise mutual information (PMI)](https://en.wikipedia.org/wiki/Pointwise_mutual_information) from item co-occurence data. This data is used by a matrix factorization model to learn item embeddings.\n","+ `sp_TrainItemMatchingModel` - Creates the `item_embedding_model` [matrix factorization](https://en.wikipedia.org/wiki/Matrix_factorization_(recommender_systems)) model. This model learns item embeddings based on the PMI data computed by `sp_ComputePMI`. \n","+ `sp_ExractEmbeddings` - Extracts the item embedding values from the `item_embedding_model` model, aggregates these values to produce a single embedding vector for each item, and stores these vectors in the `item_embeddings` table. The vector data is later exported to Cloud Storage to be used for item embedding lookup.\n","\n","Before starting this notebook, you must run the [00_prep_bq_and_datastore](00_prep_bq_and_datastore.ipynb) notebook to complete the first part of the prerequisites.\n","\n","After completing this notebook, you can run the solution either step-by-step or with a TFX pipeline:\n","\n","+ To start running the solution step-by-step, run the [01_train_bqml_mf_pmi](01_train_bqml_mf_pmi.ipynb) notebook to create item embeddings.\n","+ To run the solution by using a TFX pipeline, run the [tfx01_interactive](tfx01_interactive.ipynb) notebook to create the pipeline."]},{"cell_type":"markdown","metadata":{"id":"8XDNl5508p1q"},"source":["## Setup\r\n","\r\n","Install the required Python packages, configure the environment variables, and authenticate your GCP account."]},{"cell_type":"code","metadata":{"id":"ciAORQac8p1r"},"source":["!pip install -q -U google-cloud-bigquery pyarrow"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dn791d8i8p1s"},"source":["### Import libraries"]},{"cell_type":"code","metadata":{"id":"XdHb5Au58p1t"},"source":["import os\n","from google.cloud import bigquery"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9UFVH4xM8p1u"},"source":["### Configure GCP environment settings\r\n","\r\n","Update the following variables to reflect the values for your GCP environment:\r\n","\r\n","+ `PROJECT_ID`: The ID of the Google Cloud project you are using to implement this solution.\r\n","+ `BUCKET`: The name of the Cloud Storage bucket you created to use with this solution. The `BUCKET` value should be just the bucket name, so `myBucket` rather than `gs://myBucket`.\r\n"]},{"cell_type":"code","metadata":{"id":"gZDEzHun8p1v"},"source":["PROJECT_ID = 'yourProject' # Change to your project.\n","BUCKET = 'yourBucketName' # Change to the bucket you created.\n","SQL_SCRIPTS_DIR = 'sql_scripts'\n","BQ_DATASET_NAME = 'recommendations'\n","\n","!gcloud config set project $PROJECT_ID"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kiCcnPua8p1v"},"source":["### Authenticate your GCP account\n","This is required if you run the notebook in Colab. If you use an AI Platform notebook, you should already be authenticated."]},{"cell_type":"code","metadata":{"id":"iSg7I1e38p1w"},"source":["try:\n","  from google.colab import auth\n","  auth.authenticate_user()\n","  print(\"Colab user is authenticated.\")\n","except: pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gvIYbnii8p1x"},"source":["## Create the stored procedure dependencies"]},{"cell_type":"code","metadata":{"id":"NxvKwbdf8p1y"},"source":["%%bigquery --project $PROJECT_ID\n","\n","CREATE TABLE IF NOT EXISTS recommendations.item_cooc\n","AS SELECT 0 AS item1_Id, 0 AS item2_Id, 0 AS cooc, 0 AS pmi;"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qc5rdQap8p1z"},"source":["%%bigquery --project $PROJECT_ID\n","\n","CREATE MODEL IF NOT EXISTS recommendations.item_matching_model\n","OPTIONS(\n","    MODEL_TYPE='matrix_factorization', \n","    USER_COL='item1_Id', \n","    ITEM_COL='item2_Id',\n","    RATING_COL='score'\n",")\n","AS\n","SELECT 0 AS item1_Id, 0 AS item2_Id, 0 AS score;"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-W2Rajhs8p1z"},"source":["## Create the stored procedures\r\n","\r\n","Run the scripts that create the BigQuery stored procedures."]},{"cell_type":"code","metadata":{"id":"Cp87zCIu8p10"},"source":["client = bigquery.Client(project=PROJECT_ID)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VKXjLIqU8p11"},"source":["sql_scripts = dict()\n","\n","for script_file in [file for file in os.listdir(SQL_SCRIPTS_DIR) if '.sql' in file]:\n","  script_file_path = os.path.join(SQL_SCRIPTS_DIR, script_file)\n","  sql_script = open(script_file_path, 'r').read()\n","  sql_script = sql_script.replace('@DATASET_NAME', BQ_DATASET_NAME)\n","  sql_scripts[script_file] = sql_script"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mHq4rJYf8p12"},"source":["for script_file in sql_scripts:\n","  print(f'Executing {script_file} script...')\n","  query = sql_scripts[script_file]\n","  query_job = client.query(query)\n","  result = query_job.result()\n","\n","print('Done.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1a3kqq5Q8p12"},"source":["### List the stored procedures"]},{"cell_type":"code","metadata":{"id":"Jm5crAur8p13"},"source":["query = f'SELECT * FROM {BQ_DATASET_NAME}.INFORMATION_SCHEMA.ROUTINES;'\n","query_job = client.query(query)\n","query_job.result().to_dataframe()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qeJmhunE961u"},"source":["You can also verify that the stored procedures have been created by viewing them in the [BigQuery console](https://pantheon.corp.google.com/bigquery).\r\n"]},{"cell_type":"markdown","metadata":{"id":"mxd9Wvpi8p13"},"source":["## License\n","\n","Copyright 2020 Google LLC\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");\n","you may not use this file except in compliance with the License. You may obtain a copy of the License at: http://www.apache.org/licenses/LICENSE-2.0\n","\n","Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n","\n","See the License for the specific language governing permissions and limitations under the License.\n","\n","**This is not an official Google product but sample code provided for an educational purpose**"]}]}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-bqml-mf-embeddings.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkgce5cdOcW7"
      },
      "source": [
        "# Item-to-item Recommendation using Cooccurrence and Matrix Factorization (Part 2)\n",
        "\n",
        "This tutorial shows how to use Matrix Factorization algorithm in BigQuery ML to generate embeddings for items based on their cooccurrence statistics. The generated item embeddings can be then used to find similar items.\n",
        "\n",
        "Part 2 covers exporting the trained embeddings from the Matrix Factorization BigQuery ML Model to Cloud Storage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW1RHsqGPNzE"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp6ETYF2R-0q"
      },
      "source": [
        "!pip install -U -q apache-beam[gcp]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdSKSzqvR_qY"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcUKzLnuR_wa"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow.io as tf_io\n",
        "import apache_beam as beam\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22rDpO3JPcy9"
      },
      "source": [
        "### Configure GCP environment settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nyx4vEd7Oa9I"
      },
      "source": [
        "PROJECT_ID = 'ksalama-cloudml'\n",
        "BUCKET = 'ksalama-cloudml'\n",
        "REGION = 'europe-west2'\n",
        "BQ_DATASET_NAME = 'item_recommendations'\n",
        "BQ_TABLE_NAME = 'playlists'\n",
        "\n",
        "!gcloud config set project $PROJECT_ID"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d89ZwydPhQX"
      },
      "source": [
        "### Authenticate your GCP account\n",
        "This is required if you run the notebook in Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ICvdRicPhl8"
      },
      "source": [
        "try:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  print(\"Colab user is authenticated.\")\n",
        "except: pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1gmEmHbSaQD"
      },
      "source": [
        "## Export Trained Embeddings from BigQuery ML to Cloud Storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zowi-qSaZce"
      },
      "source": [
        "%%bigquery --project $PROJECT_ID\n",
        "\n",
        "CREATE OR REPLACE PROCEDURE item_recommendations.sp_ExractEmbeddings() \n",
        "BEGIN\n",
        "CREATE OR REPLACE TABLE  item_recommendations.item_embeddings AS\n",
        "SELECT \n",
        "  feature AS item_Id,\n",
        "  processed_input AS axis,\n",
        "  factor_weights,\n",
        "  intercept\n",
        "FROM\n",
        "  ML.WEIGHTS(MODEL `item_recommendations.item_embedding_cooc`)\n",
        "WHERE feature != 'global__INTERCEPT__';\n",
        "END"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK0olptba8qi"
      },
      "source": [
        "%%bigquery --project $PROJECT_ID\n",
        "\n",
        "CALL item_recommendations.sp_ExractEmbeddings() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg1lutQNSiKn"
      },
      "source": [
        "### Implement Beam pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1KkaHlOPixb"
      },
      "source": [
        "def get_query(dataset_name, table_name):\n",
        "  query = f'''\n",
        "    SELECT \n",
        "      item_Id,\n",
        "      axis,\n",
        "      factor_weights\n",
        "    FROM \n",
        "      `{dataset_name}.{table_name}`\n",
        "  '''\n",
        "  return query\n",
        "\n",
        "\n",
        "def parse_embeddings(bq_record):\n",
        "  item_Id = bq_record['item_Id']\n",
        "  axis = bq_record['axis']\n",
        "  intercept = bq_record['intercept']\n",
        "  factor_weights = bq_record['factor_weights']\n",
        "  dimensions = len(factor_weights)\n",
        "  embedding = [0.0] * dimensions\n",
        "  for idx, entry in enumerate(factor_weights):\n",
        "    factor, weight = entry['factor'], entry['weight']\n",
        "    embedding[int(factor) - 1] = float(weight)\n",
        "\n",
        "  return (item_Id, embedding)\n",
        "\n",
        "\n",
        "def average_embedding(entry):\n",
        "  item_id, embedding_pair = entry\n",
        "  embedding_pair = list(embedding_pair)\n",
        "  \n",
        "  if len(embedding_pair) == 2:\n",
        "    embedding1, embedding2 = embedding_pair\n",
        "    dimensions = len(embedding1)\n",
        "    embedding = [0.0] * dimensions\n",
        "    for idx in range(dimensions):\n",
        "      embedding[idx] = (embedding1[idx] + embedding2[idx]) / 2.0\n",
        "  else:\n",
        "   embedding = embedding_pair[0]\n",
        "  \n",
        "  return item_id, embedding\n",
        "\n",
        "\n",
        "def to_csv(entry):\n",
        "  item_Id, embedding = entry\n",
        "  csv_string = f'{item_Id},{item_Id},'\n",
        "  csv_string += ','.join([str(value) for value in embedding])\n",
        "  return csv_string\n",
        "\n",
        "def run_pipeline(args):\n",
        "\n",
        "    bq_dataset_name = args['bq_dataset_name']\n",
        "    embeddings_table_name = args['embeddings_table_name']\n",
        "    output_dir = args['output_dir']\n",
        "    project = args['project']\n",
        "\n",
        "    pipeline_options = beam.options.pipeline_options.PipelineOptions(**args)\n",
        "    with beam.Pipeline(options=pipeline_options) as pipeline:\n",
        "\n",
        "      query = get_query(bq_dataset_name, embeddings_table_name)\n",
        "      output_prefix = os.path.join(output_dir, 'embeddings')\n",
        "      \n",
        "      _ = (\n",
        "        pipeline\n",
        "        | 'ReadFromBigQuery' >> beam.io.Read(beam.io.BigQuerySource(\n",
        "            project=PROJECT_ID, query=query, use_standard_sql=True, flatten_results=False))\n",
        "        | 'ParseEmbeddings' >> beam.Map(parse_embeddings)\n",
        "        | 'GroupByItem' >> beam.GroupByKey()\n",
        "        | 'AverageItemEmbeddings' >> beam.Map(average_embedding)\n",
        "        | 'ConvertToCsv' >> beam.Map(to_csv)\n",
        "        | 'WriteToCloudStorage' >> beam.io.WriteToText(\n",
        "            file_path_prefix = output_prefix,\n",
        "            file_name_suffix = \".csv\")\n",
        "      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3LKaxlNSkrv"
      },
      "source": [
        "### Run pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZKaoBwnSk6U"
      },
      "source": [
        "runner = 'DataflowRunner'\n",
        "timestamp = datetime.utcnow().strftime('%y%m%d%H%M%S')\n",
        "embeddings_table_name = 'item_embeddings'\n",
        "OUTPUT_DIR = f'gs://{BUCKET}/bqml/'\n",
        "\n",
        "job_name = f'ks-bqml-export-embeddings-{timestamp}'\n",
        "\n",
        "args = {\n",
        "    'job_name': job_name,\n",
        "    'runner': runner,\n",
        "    'bq_dataset_name': BQ_DATASET_NAME,\n",
        "    'embeddings_table_name': embeddings_table_name,\n",
        "    'output_dir': OUTPUT_DIR,\n",
        "    'project': PROJECT_ID,\n",
        "    'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
        "    'region': REGION,\n",
        "}\n",
        "\n",
        "print(\"Pipeline args are set.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keud2kDLTl9p"
      },
      "source": [
        "args"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI-MXTgJTlaZ"
      },
      "source": [
        "if tf_io.gfile.exists(OUTPUT_DIR):\n",
        "  print(\"Removing {} contents...\".format(OUTPUT_DIR))\n",
        "  tf_io.gfile.rmtree(OUTPUT_DIR)\n",
        "\n",
        "print(\"Creating output: {}\".format(OUTPUT_DIR))\n",
        "tf_io.gfile.makedirs(OUTPUT_DIR)\n",
        "\n",
        "print(\"Running pipeline...\")\n",
        "%time run_pipeline(args)\n",
        "print(\"Pipeline is done.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp1bOyVCgBnH"
      },
      "source": [
        "## License\n",
        "\n",
        "Copyright 2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License. You may obtain a copy of the License at: http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
        "\n",
        "See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "**This is not an official Google product but sample code provided for an educational purpose**"
      ]
    }
  ]
}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02_export_bqml_mf_embeddings.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"environment":{"name":"tf2-2-3-gpu.2-3.m59","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dkgce5cdOcW7"},"source":["# Part 2: Process the item embedding data in BigQuery and export it to Cloud Storage\n","\n","This notebook is the second of five notebooks that guide you through running the [Real-time Item-to-item Recommendation with BigQuery ML Matrix Factorization and ScaNN](https://github.com/GoogleCloudPlatform/analytics-componentized-patterns/tree/master/retail/recommendation-system/bqml-scann) solution.\n","\n","Use this notebook to complete the following tasks:\n","\n","1. Process the song embeddings data in BigQuery to generate a single embedding vector for each song.\n","1. Use a Dataflow pipeline to write the embedding vector data to CSV files and export the files to a Cloud Storage bucket. \n","\n","Before starting this notebook, you must run the [01_train_bqml_mf_pmi](01_train_bqml_mf_pmi.ipynb) notebook to calculate item PMI data and then train a matrix factorization model with it.\n","\n","After completing this notebook, run the [03_create_embedding_lookup_model](03_create_embedding_lookup_model.ipynb) notebook to create a model to serve the item embedding data.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SW1RHsqGPNzE"},"source":["## Setup\r\n","\r\n","Import the required libraries, configure the environment variables, and authenticate your GCP account.\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"Mp6ETYF2R-0q"},"source":["!pip install -U -q apache-beam[gcp]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zdSKSzqvR_qY"},"source":["### Import libraries"]},{"cell_type":"code","metadata":{"id":"OcUKzLnuR_wa"},"source":["import os\n","import numpy as np\n","import tensorflow.io as tf_io\n","import apache_beam as beam\n","from datetime import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"22rDpO3JPcy9"},"source":["### Configure GCP environment settings\r\n","\r\n","Update the following variables to reflect the values for your GCP environment:\r\n","\r\n","+ `PROJECT_ID`: The ID of the Google Cloud project you are using to implement this solution.\r\n","+ `BUCKET`: The name of the Cloud Storage bucket you created to use with this solution. The `BUCKET` value should be just the bucket name, so `myBucket` rather than `gs://myBucket`.\r\n","+ `REGION`: The region to use for the Dataflow job."]},{"cell_type":"code","metadata":{"id":"Nyx4vEd7Oa9I"},"source":["PROJECT_ID = 'yourProject' # Change to your project.\n","BUCKET = 'yourBucketName' # Change to the bucket you created.\n","REGION = 'yourDataflowRegion' # Change to your Dataflow region.\n","BQ_DATASET_NAME = 'recommendations'\n","\n","!gcloud config set project $PROJECT_ID"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3d89ZwydPhQX"},"source":["### Authenticate your GCP account\n","This is required if you run the notebook in Colab. If you use an AI Platform notebook, you should already be authenticated."]},{"cell_type":"code","metadata":{"id":"6ICvdRicPhl8"},"source":["try:\n","  from google.colab import auth\n","  auth.authenticate_user()\n","  print(\"Colab user is authenticated.\")\n","except: pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R1gmEmHbSaQD"},"source":["## Process the item embeddings data\r\n","\r\n","You run the [sp_ExractEmbeddings](sql_scripts/sp_ExractEmbeddings.sql) stored procedure to process the item embeddings data and write the results to the `item_embeddings` table.\r\n","\r\n","This stored procedure works as follows:\r\n","\r\n","1. Uses the [ML.WEIGHTS](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-weights) function to extract the item embedding matrices from the `item_matching_model` model.\r\n","1. Aggregates these matrices to generate a single embedding vector for each item.\r\n","\r\n","    Because BigQuery ML matrix factorization models are designed for user-item recommendation use cases, they generate two embedding matrices, one for users, and the other of items. However, in this use case, both embedding matrices represent items, but in different axes of the feedback matrix. For more information about how the feedback matrix is calculated, see [Understanding item embeddings](https://cloud.google.com/solutions/real-time-item-matching#understanding_item_embeddings).\r\n"]},{"cell_type":"markdown","metadata":{"id":"utkyuwJUyTlb"},"source":["### Run the `sp_ExractEmbeddings` stored procedure"]},{"cell_type":"code","metadata":{"id":"DK0olptba8qi"},"source":["%%bigquery --project $PROJECT_ID\n","\n","CALL recommendations.sp_ExractEmbeddings() "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0UvHD7BJ8Gk0"},"source":["Get a count of the records in the `item_embeddings` table:"]},{"cell_type":"code","metadata":{"id":"pQsJenNFzVJ7"},"source":["%%bigquery --project $PROJECT_ID\n","\n","SELECT COUNT(*) embedding_count\n","FROM recommendations.item_embeddings;"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sx8JNJbA8PxC"},"source":["See a sample of the data in the `item_embeddings` table:"]},{"cell_type":"code","metadata":{"id":"Y4kTGcaRzVJ7"},"source":["%%bigquery --project $PROJECT_ID\n","\n","SELECT *\n","FROM recommendations.item_embeddings\n","LIMIT 5;"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i3LKaxlNSkrv"},"source":["## Export the item embedding vector data\n","\n","Export the item embedding data to Cloud Storage by using a Dataflow pipeline. This pipeline does the following:\n","\n","1. Reads the item embedding records from the `item_embeddings` table in BigQuery.\n","1. Writes each item embedding record to a CSV file.\n","1. Writes the item embedding CSV files to a Cloud Storage bucket.\n","\n","The pipeline in implemented in the [embeddings_exporter/pipeline.py](embeddings_exporter/pipeline.py) module."]},{"cell_type":"markdown","metadata":{"id":"G8HLFGGl5oac"},"source":["### Configure the pipeline variables\r\n","\r\n","Configure the variables needed by the pipeline:"]},{"cell_type":"code","metadata":{"id":"2ZKaoBwnSk6U"},"source":["runner = 'DataflowRunner'\n","timestamp = datetime.utcnow().strftime('%y%m%d%H%M%S')\n","job_name = f'ks-bqml-export-embeddings-{timestamp}'\n","bq_dataset_name = BQ_DATASET_NAME\n","embeddings_table_name = 'item_embeddings'\n","output_dir = f'gs://{BUCKET}/bqml/item_embeddings'\n","project = PROJECT_ID\n","temp_location = os.path.join(output_dir, 'tmp')\n","region = REGION\n","\n","print(f'runner: {runner}')\n","print(f'job_name: {job_name}')\n","print(f'bq_dataset_name: {bq_dataset_name}')\n","print(f'embeddings_table_name: {embeddings_table_name}')\n","print(f'output_dir: {output_dir}')\n","print(f'project: {project}')\n","print(f'temp_location: {temp_location}')\n","print(f'region: {region}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OyiIh-ATzVJ8"},"source":["try: os.chdir(os.path.join(os.getcwd(), 'embeddings_exporter'))\n","except: pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AHxODaoFzVJ8"},"source":["### Run the pipeline"]},{"cell_type":"markdown","metadata":{"id":"OBarPrE_-LJr"},"source":["It takes about 5 minutes to run the pipeline. You can see the graph for the running pipeline in the [Dataflow Console](https://console.cloud.google.com/dataflow/jobs)."]},{"cell_type":"code","metadata":{"id":"WngoWnt2zVJ9"},"source":["if tf_io.gfile.exists(output_dir):\n","  print(\"Removing {} contents...\".format(output_dir))\n","  tf_io.gfile.rmtree(output_dir)\n","\n","print(\"Creating output: {}\".format(output_dir))\n","tf_io.gfile.makedirs(output_dir)\n","\n","!python runner.py \\\n","  --runner={runner} \\\n","  --job_name={job_name} \\\n","  --bq_dataset_name={bq_dataset_name} \\\n","  --embeddings_table_name={embeddings_table_name} \\\n","  --output_dir={output_dir} \\\n","  --project={project} \\\n","  --temp_location={temp_location} \\\n","  --region={region}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PLXGq4CA_Oz0"},"source":["### List the CSV files that were written to Cloud Storage"]},{"cell_type":"code","metadata":{"id":"Ee89jHK5zVJ9"},"source":["!gsutil ls {output_dir}/embeddings-*.csv"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fp1bOyVCgBnH"},"source":["## License\n","\n","Copyright 2020 Google LLC\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");\n","you may not use this file except in compliance with the License. You may obtain a copy of the License at: http://www.apache.org/licenses/LICENSE-2.0\n","\n","Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n","\n","See the License for the specific language governing permissions and limitations under the License.\n","\n","**This is not an official Google product but sample code provided for an educational purpose**"]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"environment":{"name":"tf2-2-3-gpu.2-3.m59","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"},"colab":{"name":"05_deploy_lookup_and_scann_caip.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"59DnLe66_RSq"},"source":["# Part 5: Deploy the solution to AI Platform Prediction\n","\n","This notebook is the fifth of five notebooks that guide you through running the [Real-time Item-to-item Recommendation with BigQuery ML Matrix Factorization and ScaNN](https://github.com/GoogleCloudPlatform/analytics-componentized-patterns/tree/master/retail/recommendation-system/bqml-scann) solution.\n","\n","Use this notebook to complete the following tasks:\n","\n","1. Deploy the embedding lookup model to AI Platform Prediction. \n","2. Deploy the ScaNN matching service to AI Platform Prediction by using a custom container. The ScaNN matching service is an application that wraps the ANN index model and provides additional functionality, like mapping item IDs to item embeddings.\n","3. Optionally, export and deploy the matrix factorization model to AI Platform for exact matching.\n","\n","Before starting this notebook, you must run the [04_build_embeddings_scann](04_build_embeddings_scann.ipynb) notebook to build an approximate nearest neighbor (ANN) index for the item embeddings.\n"]},{"cell_type":"markdown","metadata":{"id":"--twfVSH_RSx"},"source":["## Setup\r\n","\r\n","Import the required libraries, configure the environment variables, and authenticate your GCP account."]},{"cell_type":"markdown","metadata":{"id":"hTf9yuUI_RSy"},"source":["### Import libraries"]},{"cell_type":"code","metadata":{"id":"-74hbUcn_RSy"},"source":["import numpy as np\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G0-pepnt_RSz"},"source":["### Configure GCP environment settings\r\n","\r\n","Update the following variables to reflect the values for your GCP environment:\r\n","\r\n","+ `PROJECT_ID`: The ID of the Google Cloud project you are using to implement this solution.\r\n","+ `PROJECT_NUMBER`: The number of the Google Cloud project you are using to implement this solution. You can find this in the **Project info** card on the [project dashboard page](https://pantheon.corp.google.com/home/dashboard).\r\n","+ `BUCKET`: The name of the Cloud Storage bucket you created to use with this solution. The `BUCKET` value should be just the bucket name, so `myBucket` rather than `gs://myBucket`.\r\n","+ `REGION`: The region to use for the AI Platform Prediction job."]},{"cell_type":"code","metadata":{"id":"7JijghSw_RSz"},"source":["PROJECT_ID = 'yourProject' # Change to your project.\n","PROJECT_NUMBER = 'yourProjectNumber' # Change to your project number\n","BUCKET = 'yourBucketName' # Change to the bucket you created.\n","REGION = 'yourPredictionRegion' # Change to your AI Platform Prediction region.\n","ARTIFACTS_REPOSITORY_NAME = 'ml-serving'\n","\n","EMBEDDNIG_LOOKUP_MODEL_OUTPUT_DIR = f'gs://{BUCKET}/bqml/embedding_lookup_model'\n","EMBEDDNIG_LOOKUP_MODEL_NAME = 'item_embedding_lookup'\n","EMBEDDNIG_LOOKUP_MODEL_VERSION = 'v1'\n","\n","INDEX_DIR = f'gs://{BUCKET}/bqml/scann_index'\n","SCANN_MODEL_NAME = 'index_server'\n","SCANN_MODEL_VERSION = 'v1'\n","\n","KIND = 'song'\n","\n","!gcloud config set project $PROJECT_ID"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sRgHeeDH_RS0"},"source":["### Authenticate your GCP account\n","This is required if you run the notebook in Colab. If you use an AI Platform notebook, you should already be authenticated."]},{"cell_type":"code","metadata":{"id":"mCRUZhqy_RS1"},"source":["try:\n","  from google.colab import auth\n","  auth.authenticate_user()\n","  print(\"Colab user is authenticated.\")\n","except: pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dTdkkpNL_RS1"},"source":["## Deploy the embedding lookup model to AI Platform Prediction\r\n","\r\n","Create the embedding lookup model resource in AI Platform:"]},{"cell_type":"code","metadata":{"id":"e_4hhSxr_RS2"},"source":["!gcloud ai-platform models create {EMBEDDNIG_LOOKUP_MODEL_NAME} --region={REGION}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nOLmODpvPSvk"},"source":["Next, deploy the model:"]},{"cell_type":"code","metadata":{"id":"o8QANnrC_RS2"},"source":["!gcloud ai-platform versions create {EMBEDDNIG_LOOKUP_MODEL_VERSION} \\\n","  --region={REGION} \\\n","  --model={EMBEDDNIG_LOOKUP_MODEL_NAME} \\\n","  --origin={EMBEDDNIG_LOOKUP_MODEL_OUTPUT_DIR} \\\n","  --runtime-version=2.2 \\\n","  --framework=TensorFlow \\\n","  --python-version=3.7 \\\n","  --machine-type=n1-standard-2\n","\n","print(\"The model version is deployed to AI Platform Prediction.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p9Y0KD-CPXw1"},"source":["Once the model is deployed, you can verify it in the [AI Platform console](https://pantheon.corp.google.com/ai-platform/models)."]},{"cell_type":"markdown","metadata":{"id":"6gwpUx9q_RS3"},"source":["### Test the deployed embedding lookup AI Platform Prediction model\r\n","\r\n","Set the AI Platform Prediction API information:"]},{"cell_type":"code","metadata":{"id":"6a_V-ueo_RS3"},"source":["import googleapiclient.discovery\n","from google.api_core.client_options import ClientOptions\n","\n","api_endpoint = f'https://{REGION}-ml.googleapis.com'\n","client_options = ClientOptions(api_endpoint=api_endpoint)\n","service = googleapiclient.discovery.build(\n","    serviceName='ml', version='v1', client_options=client_options)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FTucyodISTFi"},"source":["Run the `caip_embedding_lookup` method to retrieve item embeddings. This method accepts item IDs, calls the embedding lookup model in AI Platform Prediction, and returns the appropriate embedding vectors.\r\n"]},{"cell_type":"code","metadata":{"id":"y0PYGzvV_RS4"},"source":["def caip_embedding_lookup(input_items):\n","  request_body = {'instances': input_items}\n","  service_name = f'projects/{PROJECT_ID}/models/{EMBEDDNIG_LOOKUP_MODEL_NAME}/versions/{EMBEDDNIG_LOOKUP_MODEL_VERSION}'\n","  print(f'Calling : {service_name}')\n","  response = service.projects().predict(\n","    name=service_name, body=request_body).execute()\n","\n","  if 'error' in response:\n","    raise RuntimeError(response['error'])\n","\n","  return response['predictions']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NBNQXyIkEz-q"},"source":["Test the `caip_embedding_lookup` method with three item IDs:"]},{"cell_type":"code","metadata":{"id":"180KDniX_RS4"},"source":["input_items = ['2114406', '2114402 2120788', 'abc123']\n","\n","embeddings = caip_embedding_lookup(input_items)\n","print(f'Embeddings retrieved: {len(embeddings)}')\n","for idx, embedding in enumerate(embeddings):\n","  print(f'{input_items[idx]}: {embedding[:5]}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kZD4MK5k-VGD"},"source":["## ScaNN matching service\r\n","\r\n","The ScaNN matching service performs the following steps:\r\n","\r\n","1. Receives one or more item IDs from the client.\r\n","1. Calls the embedding lookup model to fetch the embedding vectors of those item IDs.\r\n","1. Uses these embedding vectors to query the ANN index to find approximate nearest neighbor embedding vectors.\r\n","1. Maps the approximate nearest neighbors embedding vectors to their corresponding item IDs.\r\n","1. Sends the item IDs back to the client.\r\n","\r\n","When the client receives the item IDs of the matches, the song title and artist information is fetched from Datastore in real-time to be displayed and served to the client application.\r\n","\r\n","Note: In practice, recommendation systems combine matches (from one or more indices) with user-provided filtering clauses (like where price <= *value* and colour =red), as well as other item metadata (like item categories, popularity, and recency) to ensure recommendation freshness and diversity. In addition, ranking is commonly applied after generating the matches to decide the order in which they are served to the user. "]},{"cell_type":"markdown","metadata":{"id":"P0L5qYS1hpl3"},"source":["### ScaNN matching service implementation\r\n","\r\n","The ScaNN matching service is implemented as a [Flask](https://flask.palletsprojects.com/en/1.1.x/quickstart/) application that runs on a [gunicorn](https://gunicorn.org/) web server. This application is implemented in the [main.py](index_server/main.py) module.\r\n","\r\n","The ScaNN matching service application works as follows:\r\n","\r\n","1. Uses environmental variables to set configuration information, such as the Google Cloud location of the ScaNN index to load.\r\n","1. Loads the ScaNN index as the `ScaNNMatcher` object is initiated.\r\n","1. As [required by AI Platform Prediction](https://cloud.google.com/ai-platform/prediction/docs/custom-container-requirements), exposes two HTTP endpoints:\r\n","    \r\n","    + `health`: a `GET` method to which AI Platform Prediction sends health checks.\r\n","    + `predict`: a `POST` method to which AI Platform Prediction forwards prediction requests.\r\n","\r\n","    The `predict` method expects JSON requests in the form `{\"instances\":[{\"query\": \"item123\", \"show\": 10}]}`, where `query` represents the item ID to retrieve matches for, and `show` represents the number of matches to retrieve.\r\n","    \r\n","    The `predict` method works as follows:\r\n","\r\n","        1. Validates the received request object.\r\n","        1. Extracts the `query` and `show` values from the request object.\r\n","        1. Calls `embedding_lookup.lookup` with the given query item ID to get its embedding vector from the embedding lookup model.\r\n","        1. Calls `scann_matcher.match` with the query item embedding vector to retrieve its approximate nearest neighbor item IDs from the ANN Index.\r\n","The list of matching item IDs are put into JSON format and returned as the response of the `predict` method."]},{"cell_type":"markdown","metadata":{"id":"eaeXo9prFNpL"},"source":["## Deploy the ScaNN matching service to AI Platform Prediction\r\n","\r\n","Package the ScaNN matching service application in a custom container and deploy it to AI Platform Prediction."]},{"cell_type":"markdown","metadata":{"id":"qkpwIGnb_RS5"},"source":["### Create an Artifact Registry for the Docker container image"]},{"cell_type":"code","metadata":{"id":"ru4oMDt2_RS5"},"source":["!gcloud beta artifacts repositories create {ARTIFACTS_REPOSITORY_NAME} \\\n","  --location={REGION} \\\n","  --repository-format=docker"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fIhDsllM_RS6"},"source":["!gcloud beta auth configure-docker {REGION}-docker.pkg.dev --quiet"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eTG7nvvt_RS6"},"source":["### Use Cloud Build to build the Docker container image\n","\n","The container runs the gunicorn HTTP web server and executes the Flask [app](https://github.com/GoogleCloudPlatform/analytics-componentized-patterns/blob/315040032df26d7cef3a26e5def35ca50dd559d6/retail/recommendation-system/bqml-scann/index_server/main.py#L35) variable defined in the `main.py` module.\n","\n","The container image to deploy to AI Platform Prediction is defined in a [Dockerfile](index_server/Dockerfile), as shown in the following code snippet:\n","\n","```\n","FROM python:3.8-slim\n","\n","COPY requirements.txt .\n","RUN pip install -r requirements.txt\n","\n","COPY . ./\n","\n","ARG PORT\n","ENV PORT=$PORT\n","\n","CMD exec gunicorn --bind :$PORT main:app  --workers=1 --threads 8 --timeout 1800\n","```\n","\n","Build the container image by using Cloud Build and specifying the [cloudbuild.yaml](index_server/cloudbuild.yaml) file:\n"]},{"cell_type":"code","metadata":{"id":"QVopE8-0_RS6"},"source":["IMAGE_URL = f'{REGION}-docker.pkg.dev/{PROJECT_ID}/{ARTIFACTS_REPOSITORY_NAME}/{SCANN_MODEL_NAME}:{SCANN_MODEL_VERSION}'\n","PORT=5001\n","\n","SUBSTITUTIONS = ''\n","SUBSTITUTIONS += f'_IMAGE_URL={IMAGE_URL},'\n","SUBSTITUTIONS += f'_PORT={PORT}'\n","\n","!gcloud builds submit --config=index_server/cloudbuild.yaml \\\n","  --substitutions={SUBSTITUTIONS} \\\n","  --timeout=1h"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TPk9Qi93G56d"},"source":["Run the following command to verify the container image has been built:\r\n"]},{"cell_type":"code","metadata":{"id":"PvSIUzD9_RS7"},"source":["repository_id = f'{REGION}-docker.pkg.dev/{PROJECT_ID}/{ARTIFACTS_REPOSITORY_NAME}'\n","\n","!gcloud beta artifacts docker images list {repository_id}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UAr0Vsft_RS7"},"source":["### Create a service account for AI Platform Prediction\r\n","\r\n","Create a service account to run the custom container. This [is required](https://cloud.google.com/ai-platform/prediction/docs/custom-service-account#container-default) in cases where you want to grant specific permissions to the service account."]},{"cell_type":"code","metadata":{"id":"cBa56i5g_RS8"},"source":["SERVICE_ACCOUNT_NAME = 'caip-serving'\n","SERVICE_ACCOUNT_EMAIL = f'{SERVICE_ACCOUNT_NAME}@{PROJECT_ID}.iam.gserviceaccount.com'\n","!gcloud iam service-accounts create {SERVICE_ACCOUNT_NAME} \\\n","  --description=\"Service account for AI Platform Prediction to access cloud resources.\" "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0-5BUPqT_RS8"},"source":["Grant the `Cloud ML Engine (AI Platform)` service account the `iam.serviceAccountAdmin` privilege, and grant the `caip-serving` service account the privileges required by the ScaNN matching service, which are `storage.objectViewer` and `ml.developer`."]},{"cell_type":"code","metadata":{"id":"qUoaWCVJ_RS8"},"source":["!gcloud projects describe {PROJECT_ID} --format=\"value(projectNumber)\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LzMJ60X-_RS9"},"source":["!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n","  --role=roles/iam.serviceAccountAdmin \\\n","  --member=serviceAccount:service-{PROJECT_NUMBER}@cloud-ml.google.com.iam.gserviceaccount.com\n","\n","!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n","  --role=roles/storage.objectViewer \\\n","  --member=serviceAccount:{SERVICE_ACCOUNT_EMAIL}\n","    \n","!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n","  --role=roles/ml.developer \\\n","  --member=serviceAccount:{SERVICE_ACCOUNT_EMAIL}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1-x11wBH_RS9"},"source":["### Deploy the custom container to AI Platform Prediction\r\n","\r\n","Create the ANN index model resource in AI Platform:"]},{"cell_type":"code","metadata":{"id":"CfeleaCW_RS-"},"source":["!gcloud ai-platform models create {SCANN_MODEL_NAME} --region={REGION}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I9TcigBmHOin"},"source":["Deploy the custom container to AI Platform prediction. Note that you use the `env-vars` parameter to pass environmental variables to the Flask application in the container. "]},{"cell_type":"code","metadata":{"id":"fg9wtS2__RS_"},"source":["HEALTH_ROUTE=f'/v1/models/{SCANN_MODEL_NAME}/versions/{SCANN_MODEL_VERSION}'\n","PREDICT_ROUTE=f'/v1/models/{SCANN_MODEL_NAME}/versions/{SCANN_MODEL_VERSION}:predict'\n","\n","ENV_VARIABLES = f'PROJECT_ID={PROJECT_ID},'\n","ENV_VARIABLES += f'REGION={REGION},'\n","ENV_VARIABLES += f'INDEX_DIR={INDEX_DIR},'\n","ENV_VARIABLES += f'EMBEDDNIG_LOOKUP_MODEL_NAME={EMBEDDNIG_LOOKUP_MODEL_NAME},'\n","ENV_VARIABLES += f'EMBEDDNIG_LOOKUP_MODEL_VERSION={EMBEDDNIG_LOOKUP_MODEL_VERSION}'\n","\n","!gcloud beta ai-platform versions create {SCANN_MODEL_VERSION} \\\n","  --region={REGION} \\\n","  --model={SCANN_MODEL_NAME} \\\n","  --image={IMAGE_URL} \\\n","  --ports={PORT} \\\n","  --predict-route={PREDICT_ROUTE} \\\n","  --health-route={HEALTH_ROUTE} \\\n","  --machine-type=n1-standard-4 \\\n","  --env-vars={ENV_VARIABLES} \\\n","  --service-account={SERVICE_ACCOUNT_EMAIL}\n","\n","print(\"The model version is deployed to AI Platform Prediction.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WzCcA58l_RS_"},"source":["### Test the Deployed ScaNN Index Service\r\n","\r\n","After deploying the custom container, test it by running the `caip_scann_match` method. This method accepts the parameter `query_items`, whose value is converted into a space-separated string of item IDs and treated as a single query. That is, a single embedding vector is retrieved from the embedding lookup model, and similar item IDs are retrieved from the ScaNN index given this embedding vector."]},{"cell_type":"code","metadata":{"id":"w5OlMGuD_RS_"},"source":["from google.cloud import datastore\n","import requests\n","client = datastore.Client(PROJECT_ID)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WwzuijuH_RTA"},"source":["def caip_scann_match(query_items, show=10):\n","  request_body = {\n","      'instances': [{\n","          'query':' '.join(query_items), \n","          'show':show\n","      }]\n","   }\n","  \n","  service_name = f'projects/{PROJECT_ID}/models/{SCANN_MODEL_NAME}/versions/{SCANN_MODEL_VERSION}'\n","  print(f'Calling: {service_name}')  \n","  response = service.projects().predict(\n","    name=service_name, body=request_body).execute()\n","\n","  if 'error' in response:\n","    raise RuntimeError(response['error'])\n","\n","  match_tokens = response['predictions']\n","  keys = [client.key(KIND, int(key)) for key in match_tokens]\n","  items = client.get_multi(keys)\n","  return items\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ctXsOxhDHsX_"},"source":["Call the `caip_scann_match` method with five item IDs and request five match items for each:"]},{"cell_type":"code","metadata":{"id":"620GvSzr_RTA"},"source":["songs = {\n","    '2120788': 'Limp Bizkit: My Way',\n","    '1086322': 'Jacques Brel: Ne Me Quitte Pas',\n","    '833391': 'Ricky Martin: Livin\\' la Vida Loca',\n","    '1579481': 'Dr. Dre: The Next Episode',\n","    '2954929': 'Black Sabbath: Iron Man'\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YiYAYVG9_RTB"},"source":["for item_Id, desc in songs.items():\n","  print(desc)\n","  print(\"==================\")\n","  similar_items = caip_scann_match([item_Id], 5)\n","  for similar_item in similar_items:\n","    print(f'- {similar_item[\"artist\"]}: {similar_item[\"track_title\"]}')\n","  print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lt7-YDSe_RTB"},"source":["## (Optional) Deploy the matrix factorization model to AI Platform Prediction\r\n","\r\n","Optionally, you can deploy the matrix factorization model in order to perform exact item matching. The model takes `Item1_Id` as an input and outputs the top 50 recommended `item2_Ids`.\r\n","\r\n","Exact matching returns better results, but takes significantly longer than approximate nearest neighbor matching. You might want to use exact item matching in cases where you are working with a very small data set and where latency isn't a primary concern."]},{"cell_type":"markdown","metadata":{"id":"YSDzSk4T_RTC"},"source":["### Export the model from BigQuery ML to Cloud Storage as a SavedModel"]},{"cell_type":"code","metadata":{"id":"YVmmFvLk_RTC"},"source":["BQ_DATASET_NAME = 'recommendations'\n","BQML_MODEL_NAME = 'item_matching_model'\n","BQML_MODEL_VERSION = 'v1' \n","BQML_MODEL_OUTPUT_DIR = f'gs://{BUCKET}/bqml/item_matching_model'\n","\n","!bq --quiet extract -m {BQ_DATASET_NAME}.{BQML_MODEL_NAME} {BQML_MODEL_OUTPUT_DIR}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q4xzyUte_RTC"},"source":["!saved_model_cli show --dir {BQML_MODEL_OUTPUT_DIR} --tag_set serve --signature_def serving_default"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kWbEnUnO_RTC"},"source":["### Deploy the exact matching model to AI Platform Prediction"]},{"cell_type":"code","metadata":{"id":"Es8Tp9HM_RTD"},"source":["!gcloud ai-platform models create {BQML_MODEL_NAME} --region={REGION}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nNOVgOD9_RTD"},"source":["!gcloud ai-platform versions create {BQML_MODEL_VERSION} \\\n","  --region={REGION} \\\n","  --model={BQML_MODEL_NAME} \\\n","  --origin={BQML_MODEL_OUTPUT_DIR} \\\n","  --runtime-version=2.2 \\\n","  --framework=TensorFlow \\\n","  --python-version=3.7 \\\n","  --machine-type=n1-standard-2\n","\n","print(\"The model version is deployed to AI Platform Predicton.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n9MDaT3P_RTD"},"source":["def caip_bqml_matching(input_items, show):\n","  request_body = {'instances': input_items}\n","  service_name = f'projects/{PROJECT_ID}/models/{BQML_MODEL_NAME}/versions/{BQML_MODEL_VERSION}'\n","  print(f'Calling : {service_name}')\n","  response = service.projects().predict(\n","    name=service_name, body=request_body).execute()\n","\n","  if 'error' in response:\n","    raise RuntimeError(response['error'])\n","    \n","  \n","  match_tokens = response['predictions'][0][\"predicted_item2_Id\"][:show]\n","  keys = [client.key(KIND, int(key)) for key in match_tokens]\n","  items = client.get_multi(keys)\n","  return items\n","\n","  return response['predictions']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bHvFNZ78_RTD"},"source":["for item_Id, desc in songs.items():\n","  print(desc)\n","  print(\"==================\")\n","  similar_items = caip_bqml_matching([int(item_Id)], 5)\n","  for similar_item in similar_items:\n","    print(f'- {similar_item[\"artist\"]}: {similar_item[\"track_title\"]}')\n","  print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6uUOZgLQ_RTE"},"source":["## License\n","\n","Copyright 2020 Google LLC\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");\n","you may not use this file except in compliance with the License. You may obtain a copy of the License at: http://www.apache.org/licenses/LICENSE-2.0\n","\n","Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n","\n","See the License for the specific language governing permissions and limitations under the License.\n","\n","**This is not an official Google product but sample code provided for an educational purpose**"]}]}
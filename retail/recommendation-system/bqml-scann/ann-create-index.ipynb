{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-latency item-to-item recommendation system - Creating ANN index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook is a part of the series that describes the process of implementing a [**Low-latency item-to-item recommendation system**](https://github.com/jarokaz/analytics-componentized-patterns/tree/master/retail/recommendation-system/bqml-scann).\n",
    "\n",
    "The notebook demonstrates how to create and deploy an ANN index using embeddings created in the preceding notebooks. In this notebook you go through the following steps.\n",
    "\n",
    "1. Exporting embeddings from BigQuery into the JSONL formated file.\n",
    "2. Creating an ANN Index using the exported embeddings.\n",
    "3. Creating and ANN Endpoint. \n",
    "4. Deploying the ANN Index to the ANN Endpoint.\n",
    "5. Testing the deployed ANN Index.\n",
    "\n",
    "This notebook was designed to run on [AI Platform Notebooks](https://cloud.google.com/ai-platform/notebooks/docs) using the standard TensorFlow 2.3 image. Your notebook instance should be in the same project as the AI Platform ANN Service.\n",
    "\n",
    "While AI Platform ANN Service is in the Experimental stage your project must be allow-listed before using the service. Contact `gcp-ann-feedback@` to allow list your project and user id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the notebook's environment\n",
    "\n",
    "### Configuring AI Platform ANN Service\n",
    "\n",
    "#### Enable the required Cloud APIs\n",
    "\n",
    "You need to enable the following APIs to use the ANN service:\n",
    "* aiplatform.googleapis.com\n",
    "* servicenetworking.googleapis.com\n",
    "* compute.googleapis.com\n",
    "\n",
    "#### Prepare a VPC network\n",
    "\n",
    "In the experimental release, ANN service is only accessible using private endpoints. Before using the service you need to have a [VPC network](https://cloud.google.com/vpc) configured with [private services access](https://cloud.google.com/vpc/docs/configure-private-services-access). You can use the `default` VPC or create a new one.\n",
    "\n",
    "The below instructions are for a VPC that was created with auto subnets and regional dynamic routing mode (defaults). It is recommended that you execute the below commands from Cloud Shell, using the account with appropriate permissions - `roles/compute.networkAdmin`.\n",
    "\n",
    "1. Set environment variables for your project ID, the name of your VPC network, and the name of your reserved range of addresses. The name of the reserved range can be an arbitrary name. It is for display only.\n",
    "\n",
    "```\n",
    "PROJECT_ID=<your-project-id>\n",
    "gcloud config set project $PROJECT_ID\n",
    "NETWORK_NAME=<your-VPC-network-name>\n",
    "PEERING_RANGE_NAME=google-reserved-range\n",
    "\n",
    "```\n",
    "\n",
    "2. Reserve an IP range for Google services. The reserved range should be large enought to accommodate all peered services. The below command reserves a CIDR block with mask /16\n",
    "\n",
    "```\n",
    "gcloud compute addresses create $PEERING_RANGE_NAME \\\n",
    "  --global \\\n",
    "  --prefix-length=16 \\\n",
    "  --description=\"peering range for Google service: AI Platform Online Prediction\" \\\n",
    "  --network=$NETWORK_NAME \\\n",
    "  --purpose=VPC_PEERING \\\n",
    "  --project=$PROJECT_ID\n",
    "\n",
    "```\n",
    "\n",
    "3. Create a private connection to establish a VPC Network Peering between your VPC network and the Google services network.\n",
    "\n",
    "```\n",
    "gcloud services vpc-peerings connect \\\n",
    "  --service=servicenetworking.googleapis.com \\\n",
    "  --network=$NETWORK_NAME \\\n",
    "  --ranges=$PEERING_RANGE_NAME \\\n",
    "  --project=$PROJECT_ID\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing notebook dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import grpc\n",
    "\n",
    "import google.auth\n",
    "import numpy as np\n",
    "import tensorflow.io as tf_io\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from typing import List, Optional, Text, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the experimental release, the Online Querying API of the deployed ANN index is exposed throught the GRPC interface. The `ann_grpc` folder contains the grpc client stub to interface to the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_GRPC_ENDPOINT_STUB = 'ann_grpc'\n",
    "if ANN_GRPC_ENDPOINT_STUB not in sys.path:\n",
    "    sys.path.append(ANN_GRPC_ENDPOINT_STUB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ann_grpc.match_pb2_grpc as match_pb2_grpc\n",
    "import ann_grpc.match_pb2 as match_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure GCP environment\n",
    "\n",
    "Set the following constants to the values reflecting your environment:\n",
    "\n",
    "* `PROJECT_ID` - your GCP project ID.\n",
    "* `PROJECT_NUMBER` - your GCP project number.\n",
    "* `BQ_DATASET_NAME` - the name of the BigQuery dataset that contains the item embeddings table.\n",
    "* `BQ_LOCATION` - the dataset location\n",
    "* `DATA_LOCATION` - a GCS location for the exported embeddings (JSONL) files.\n",
    "* `VPC_NAME` - a name of the GCP VPC to use for the index deployments. Use the name of the VPC prepared in the previous section. \n",
    "* `REGION` - a compute region. Don't change the default - `us-central` - while the ANN Service is in the experimental stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jk-mlops-dev' # <-CHANGE THIS\n",
    "PROJECT_NUMBER = '895222332033' # <-CHANGE THIS\n",
    "BQ_DATASET_NAME = 'song_embeddings' # <- CHANGE THIS\n",
    "BQ_LOCATION = 'US' # <- CHANGE THIS\n",
    "DATA_LOCATION = 'gs://jk-ann-staging/embeddings' # <-CHANGE THIS\n",
    "VPC_NAME = 'default' # <-CHANGE THIS\n",
    "\n",
    "EMBEDDINGS_TABLE = 'item_embeddings'\n",
    "REGION = 'us-central1'\n",
    "MATCH_SERVICE_PORT = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the embeddings\n",
    "\n",
    "In the preceeding notebookes you trained the Matrix Factorization BQML model and exported the embeddings to the `item_embeddings` table. \n",
    "\n",
    "In this step you will extract the embeddings to a set of JSONL files in the format required by the ANN service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the number of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client(project=PROJECT_ID, location=BQ_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   embedding_count\n",
       "0            35519"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    SELECT COUNT(*) embedding_count\n",
    "    FROM {BQ_DATASET_NAME}.item_embeddings;\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.job.ExtractJob at 0x7fcc0a9675d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_pattern = 'embedding-*.json'\n",
    "destination_uri = f'{DATA_LOCATION}/{file_name_pattern}'\n",
    "table_id = 'item_embeddings'\n",
    "destination_format = 'NEWLINE_DELIMITED_JSON'\n",
    "\n",
    "dataset_ref = bigquery.DatasetReference(PROJECT_ID, BQ_DATASET_NAME)\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "job_config = bigquery.job.ExtractJobConfig()\n",
    "job_config.destination_format = bigquery.DestinationFormat.NEWLINE_DELIMITED_JSON\n",
    "\n",
    "extract_job = client.extract_table(\n",
    "    table_ref,\n",
    "    destination_uris=destination_uri,\n",
    "    job_config=job_config,\n",
    "    #location=BQ_LOCATION,\n",
    ")  \n",
    "\n",
    "extract_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the extracted files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://jk-ann-staging/embeddings/embedding-000000000000.json\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls {DATA_LOCATION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an ANN index deployment\n",
    "\n",
    "Deploying an ANN index is a 3 step process:\n",
    "1. Creating an index from source files\n",
    "2. Creating an endpoint to access the index\n",
    "3. Deploying the index to the endpoint\n",
    "\n",
    "\n",
    "You will use the REST interface to invoke the AI Platform ANN Service Control Plane API that manages indexes, endpoints, and deployments.\n",
    "\n",
    "After the index has been deployed you can submit matching requests using Online Querying API. In the experimental stage this API is only accessible through the gRPC interface.\n",
    "\n",
    "Refer to [ANN service user guide](https://docs.google.com/document/d/1D5HsS829UuYUuyCTHWSFqR8dl4KNvL9C82nEs9vLtjg/edit) for more information about the ANN Service APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper classes to encapsulate the ANN Service REST API.\n",
    "\n",
    "Currently, there is no Python client that encapsulates the ANN Service Control Plane API. The below code snippet defines a simple wrapper that encapsulates a subset of REST APIs used in this notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNClient(object):\n",
    "    \"\"\"Base ANN Service client.\"\"\"\n",
    "    \n",
    "    def __init__(self, project_id, project_number, region):\n",
    "        credentials, _ = google.auth.default()\n",
    "        self.authed_session = google.auth.transport.requests.AuthorizedSession(credentials)\n",
    "        self.ann_endpoint = f'{region}-aiplatform.googleapis.com'\n",
    "        self.ann_parent = f'https://{self.ann_endpoint}/v1alpha1/projects/{project_id}/locations/{region}'\n",
    "        self.project_id = project_id\n",
    "        self.project_number = project_number\n",
    "        self.region = region\n",
    "        \n",
    "    def wait_for_completion(self, operation_id, message, sleep_time):\n",
    "        \"\"\"Waits for a completion of a long running operation.\"\"\"\n",
    "        \n",
    "        api_url = f'{self.ann_parent}/operations/{operation_id}'\n",
    "\n",
    "        start_time = datetime.datetime.utcnow()\n",
    "        while True:\n",
    "            response = self.authed_session.get(api_url)\n",
    "            if 'done' in response.json().keys():\n",
    "                logging.info('Operation completed!')\n",
    "                break\n",
    "            elapsed_time = datetime.datetime.utcnow() - start_time\n",
    "            logging.info('{}. Elapsed time since start: {}.'.format(\n",
    "                message, str(elapsed_time)))\n",
    "            time.sleep(sleep_time)\n",
    "    \n",
    "        return response.json()['response']\n",
    "\n",
    "\n",
    "class IndexClient(ANNClient):\n",
    "    \"\"\"Encapsulates a subset of control plane APIs \n",
    "    that manage ANN indexes.\"\"\"\n",
    "\n",
    "    def __init__(self, project_id, project_number, region):\n",
    "        super().__init__(project_id, project_number, region)\n",
    "\n",
    "    def create_index(self, display_name, description, metadata):\n",
    "        \"\"\"Creates an ANN Index.\"\"\"\n",
    "    \n",
    "        api_url = f'{self.ann_parent}/indexes'\n",
    "    \n",
    "        request_body = {\n",
    "            'display_name': display_name,\n",
    "            'description': description,\n",
    "            'metadata': metadata\n",
    "        }\n",
    "    \n",
    "        response = self.authed_session.post(api_url, data=json.dumps(request_body))\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "        operation_id = response.json()['name'].split('/')[-1]\n",
    "        \n",
    "        return operation_id\n",
    "\n",
    "    def list_indexes(self, display_name=None):\n",
    "        \"\"\"Lists all indexes with a given display name or\n",
    "        all indexes if the display_name is not provided.\"\"\"\n",
    "    \n",
    "        if display_name:\n",
    "            api_url = f'{self.ann_parent}/indexes?filter=display_name=\"{display_name}\"'\n",
    "        else:\n",
    "            api_url = f'{self.ann_parent}/indexes'\n",
    "\n",
    "        response = self.authed_session.get(api_url).json()\n",
    "\n",
    "        return response['indexes'] if response else []\n",
    "    \n",
    "    def delete_index(self, index_id):\n",
    "        \"\"\"Deletes an ANN index.\"\"\"\n",
    "        \n",
    "        api_url = f'{self.ann_parent}/indexes/{index_id}'\n",
    "        response = self.authed_session.delete(api_url)\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "\n",
    "\n",
    "class IndexDeploymentClient(ANNClient):\n",
    "    \"\"\"Encapsulates a subset of control plane APIs \n",
    "    that manage ANN endpoints and deployments.\"\"\"\n",
    "    \n",
    "    def __init__(self, project_id, project_number, region):\n",
    "        super().__init__(project_id, project_number, region)\n",
    "\n",
    "    def create_endpoint(self, display_name, vpc_name):\n",
    "        \"\"\"Creates an ANN endpoint.\"\"\"\n",
    "    \n",
    "        api_url = f'{self.ann_parent}/indexEndpoints'\n",
    "        network_name = f'projects/{self.project_number}/global/networks/{vpc_name}'\n",
    "\n",
    "        request_body = {\n",
    "            'display_name': display_name,\n",
    "            'network': network_name\n",
    "        }\n",
    "\n",
    "        response = self.authed_session.post(api_url, data=json.dumps(request_body))\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "        operation_id = response.json()['name'].split('/')[-1]\n",
    "    \n",
    "        return operation_id\n",
    "    \n",
    "    def list_endpoints(self, display_name=None):\n",
    "        \"\"\"Lists all ANN endpoints with a given display name or\n",
    "        all endpoints in the project if the display_name is not provided.\"\"\"\n",
    "        \n",
    "        if display_name:\n",
    "            api_url = f'{self.ann_parent}/indexEndpoints?filter=display_name=\"{display_name}\"'\n",
    "        else:\n",
    "            api_url = f'{self.ann_parent}/indexEndpoints'\n",
    "\n",
    "        response = self.authed_session.get(api_url).json()\n",
    " \n",
    "        return response['indexEndpoints'] if response else []\n",
    "    \n",
    "    def delete_endpoint(self, endpoint_id):\n",
    "        \"\"\"Deletes an ANN endpoint.\"\"\"\n",
    "        \n",
    "        api_url = f'{self.ann_parent}/indexEndpoints/{endpoint_id}'\n",
    "        \n",
    "        response = self.authed_session.delete(api_url)\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "        \n",
    "        return response.json()\n",
    "    \n",
    "    def create_deployment(self, display_name, deployment_id, endpoint_id, index_id):\n",
    "        \"\"\"Deploys an ANN index to an endpoint.\"\"\"\n",
    "    \n",
    "        api_url = f'{self.ann_parent}/indexEndpoints/{endpoint_id}:deployIndex'\n",
    "        index_name = f'projects/{self.project_number}/locations/{self.region}/indexes/{index_id}'\n",
    "\n",
    "        request_body = {\n",
    "            'deployed_index': {\n",
    "                'id': deployment_id,\n",
    "                'index': index_name,\n",
    "                'display_name': display_name\n",
    "            }\n",
    "        }\n",
    "\n",
    "        response = self.authed_session.post(api_url, data=json.dumps(request_body))\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "        operation_id = response.json()['name'].split('/')[-1]\n",
    "        \n",
    "        return operation_id\n",
    "    \n",
    "    def get_deployment_grpc_ip(self, endpoint_id, deployment_id):\n",
    "        \"\"\"Returns a private IP address for a gRPC interface to \n",
    "        an Index deployment.\"\"\"\n",
    "  \n",
    "        api_url = f'{self.ann_parent}/indexEndpoints/{endpoint_id}'\n",
    "\n",
    "        response = self.authed_session.get(api_url)\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "            \n",
    "        endpoint_ip = None\n",
    "        if 'deployedIndexes' in response.json().keys():\n",
    "            for deployment in response.json()['deployedIndexes']:\n",
    "                if deployment['id'] == deployment_id:\n",
    "                    endpoint_ip = deployment['privateEndpoints']['matchGrpcAddress']\n",
    "                    \n",
    "        return endpoint_ip\n",
    "\n",
    "    \n",
    "    def delete_deployment(self, endpoint_id, deployment_id):\n",
    "        \"\"\"Undeployes an index from an endpoint.\"\"\"\n",
    "        \n",
    "        api_url = f'{self.ann_parent}/indexEndpoints/{endpoint_id}:undeployIndex'\n",
    "        \n",
    "        request_body = {\n",
    "            'deployed_index_id': deployment_id\n",
    "        }\n",
    "    \n",
    "        response = self.authed_session.post(api_url, data=json.dumps(request_body))\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    \n",
    "index_client = IndexClient(PROJECT_ID, PROJECT_NUMBER, REGION)\n",
    "deployment_client = IndexDeploymentClient(PROJECT_ID, PROJECT_NUMBER, REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an index\n",
    "\n",
    "#### List all indexes registered with the ANN service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/895222332033/locations/us-central1/indexes/2779283920041017344\n",
      "projects/895222332033/locations/us-central1/indexes/6418192418956378112\n",
      "projects/895222332033/locations/us-central1/indexes/4720335359437701120\n"
     ]
    }
   ],
   "source": [
    "indexes = index_client.list_indexes()\n",
    "\n",
    "if not indexes:\n",
    "    print('There are not any indexes registered with the service')\n",
    "\n",
    "for index in indexes:\n",
    "    print(index['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure and create a new index based on the exported embeddings\n",
    "\n",
    "Index creation is a long running operation. Be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_display_name = 'Song embeddings'\n",
    "index_description = 'Song embeddings created BQML Matrix Factorization model'\n",
    "\n",
    "index_metadata = {\n",
    "    'contents_delta_uri': DATA_LOCATION,\n",
    "    'config': {\n",
    "        'dimensions': 50,\n",
    "        'approximate_neighbors_count': 50,\n",
    "        'distance_measure_type': 'DOT_PRODUCT_DISTANCE',\n",
    "        'feature_norm_type': 'UNIT_L2_NORM',\n",
    "        'tree_ah_config': {\n",
    "            'child_node_count': 1000,\n",
    "            'max_leaves_to_search': 100\n",
    "         }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "operation_id = index_client.create_index(index_display_name, \n",
    "                                          index_description,\n",
    "                                          index_metadata)\n",
    "\n",
    "response = index_client.wait_for_completion(operation_id, 'Creating index', 20)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify that the index was created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = index_client.list_indexes(index_display_name)\n",
    "\n",
    "for index in indexes:\n",
    "    print(index['name'])\n",
    "\n",
    "if indexes: \n",
    "    index_id = index['name'].split('/')[-1]\n",
    "    print(f'Index: {index_id} will be used for deployment')\n",
    "else:\n",
    "    print('No indexes available for deployment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the index deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all endpoints registered with the ANN service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/895222332033/locations/us-central1/indexEndpoints/1908400342098247680\n"
     ]
    }
   ],
   "source": [
    "endpoints = deployment_client.list_endpoints()\n",
    "\n",
    "if not endpoints:\n",
    "    print('There are not any endpoints registered with the service')\n",
    "\n",
    "for endpoint in endpoints:\n",
    "    print(endpoint['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an index endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_display_name = 'Song embeddings endpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_id = deployment_client.create_endpoint(deployment_display_name, VPC_NAME)\n",
    "\n",
    "response = index_client.wait_for_completion(operation_id, 'Waiting for endpoint', 10)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify that the endpoint was created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No endpoints available for deployment\n"
     ]
    }
   ],
   "source": [
    "endpoints = deployment_client.list_endpoints(deployment_display_name)\n",
    "\n",
    "for endpoint in endpoints:\n",
    "    print(endpoint['name'])\n",
    "    \n",
    "if endpoints: \n",
    "    endpoint_id = endpoint['name'].split('/')[-1]\n",
    "    print(f'Endpoint: {endpoint_id} will be used for deployment')\n",
    "else:\n",
    "    print('No endpoints available for deployment')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy the index to the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set the deployment ID\n",
    "\n",
    "The ID must be unique within your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_display_name = 'Song embeddings deployed index'\n",
    "deployed_index_id = 'songs_embeddings_deployed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deploy the index\n",
    "\n",
    "Be patient. Index deployment is a long running operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_id = deployment_client.create_deployment(deployment_display_name, \n",
    "                                                   deployed_index_id,\n",
    "                                                   endpoint_id,\n",
    "                                                   index_id)\n",
    "\n",
    "response = index_client.wait_for_completion(operation_id, 'Waiting for deployment', 10)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve the gRPC private endpoint for the ANN Match service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_index_ip = deployment_client.get_deployment_grpc_ip(endpoint_id, deployed_index_id)\n",
    "endpoint = f'{deployed_index_ip}:{MATCH_SERVICE_PORT}'\n",
    "print(f'gRPC endpoint for the: {deployed_index_id} deployment is: {endpoint}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the ANN service\n",
    "\n",
    "You will use the gRPC interface to query the deployed index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a helper wrapper around the Match Service gRPC API.\n",
    "\n",
    "The wrapper uses the pre-generated gRPC stub to the Online Querying gRPC interface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchService(object):\n",
    "    \"\"\"This is a wrapper around Online Querying gRPC interface.\"\"\"\n",
    "    def __init__(self, endpoint, deployed_index_id):\n",
    "        self.endpoint = endpoint\n",
    "        self.deployed_index_id = deployed_index_id\n",
    "\n",
    "    def single_match(\n",
    "        self,\n",
    "        embedding: List[float],\n",
    "        num_neighbors: int) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Requests a match for a single embedding.\"\"\"\n",
    "    \n",
    "        match_request = match_pb2.MatchRequest(deployed_index_id=self.deployed_index_id,\n",
    "                                               float_val=embedding,\n",
    "                                               num_neighbors=num_neighbors)\n",
    "        with grpc.insecure_channel(endpoint) as channel:\n",
    "            stub = match_pb2_grpc.MatchServiceStub(channel)\n",
    "            response = stub.Match(match_request)\n",
    "    \n",
    "        return [(neighbor.id, neighbor.distance) for neighbor in response.neighbor]\n",
    "\n",
    "\n",
    "    def batch_match(\n",
    "        self,\n",
    "        embeddings: List[List[float]],\n",
    "        num_neighbors: int) -> List[List[Tuple[str, float]]]:\n",
    "        \"\"\"Requests matches ofr a list of embeddings.\"\"\"\n",
    "    \n",
    "        match_requests = [\n",
    "            match_pb2.MatchRequest(deployed_index_id=self.deployed_index_id,\n",
    "                                   float_val=embedding,\n",
    "                                   num_neighbors=num_neighbors)\n",
    "            for embedding in embeddings]\n",
    "    \n",
    "        batches_per_index = [\n",
    "            match_pb2.BatchMatchRequest.BatchMatchRequestPerIndex(\n",
    "                deployed_index_id=self.deployed_index_id,\n",
    "                requests=match_requests)]\n",
    "    \n",
    "        batch_match_request = match_pb2.BatchMatchRequest(\n",
    "            requests=batches_per_index)\n",
    "    \n",
    "        with grpc.insecure_channel(endpoint) as channel:\n",
    "            stub = match_pb2_grpc.MatchServiceStub(channel)\n",
    "            response = stub.BatchMatch(batch_match_request)\n",
    "        \n",
    "        matches = []\n",
    "        for batch_per_index in response.responses:\n",
    "            for match in batch_per_index.responses:\n",
    "                matches.append(\n",
    "                    [(neighbor.id, neighbor.distance) for neighbor in match.neighbor])\n",
    "        \n",
    "        return matches\n",
    "    \n",
    "match_service = MatchService(endpoint, deployed_index_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare sample data\n",
    "\n",
    "Retrieve a few embeddings from the BigQuery embedding table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery df_embeddings\n",
    "\n",
    "SELECT id, embedding\n",
    "FROM `recommendations.item_embeddings` \n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_embeddings = [list(embedding) for embedding in df_embeddings['embedding']]\n",
    "sample_embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a single match query\n",
    "\n",
    "The following call requests 10 closest neighbours for a single embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "single_match = match_service.single_match(sample_embeddings[0], 10)\n",
    "single_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a batch match query\n",
    "\n",
    "The following call requests 3 closest neighbours for each of the embeddings in a batch of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "batch_match = match_service.batch_match(sample_embeddings[0:5], 3)\n",
    "batch_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "**WARNING**\n",
    "\n",
    "The below code will delete all ANN deployments, endpoints, and indexes in the configured project.\n",
    "\n",
    "### Delete index deployments and endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for endpoint in deployment_client.list_endpoints():\n",
    "    endpoint_id = endpoint['name'].split('/')[-1]\n",
    "    if 'deployedIndexes' in endpoint.keys():\n",
    "        for deployment in endpoint['deployedIndexes']:\n",
    "            print('   Deleting index deployment: {} in the endpoint: {} '.format(deployment['id'], endpoint_id))\n",
    "            deployment_client.delete_deployment(endpoint_id, deployment['id'])\n",
    "    print('Deleting endpoint: {}'.format(endpoint['name']))\n",
    "    deployment_client.delete_endpoint(endpoint_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in index_client.list_indexes():\n",
    "    index_id = index['name'].split('/')[-1]\n",
    "    print('Deleting index: {}'.format(index['name']))\n",
    "    index_client.delete_index(index_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "Copyright 2020 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License. You may obtain a copy of the License at: http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
    "\n",
    "See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "**This is not an official Google product but sample code provided for an educational purpose**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m61"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

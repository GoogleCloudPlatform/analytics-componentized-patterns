{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFX - Compile and Deploy the TFX Pipeline to KFP\n",
    "\n",
    "This Notebook helps you to compile the **TFX Pipeline** to a **KFP package**. This will creat an **Argo YAML** file in a **.tar.gz** package. We perform the following steps:\n",
    "1. Build a custom container image that include our modules\n",
    "2. Compile TFX Pipeline using CLI\n",
    "3. Deploy the compiled pipeline to KFP \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U kfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set compile time variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PROJECT_ID'] = 'ksalama-cloudml' # Set your project.\n",
    "os.environ['BUCKET'] = 'ksalama-cloudml' # Set your bucket.\n",
    "os.environ['REGION'] = 'us-central1' # Set your region.\n",
    "os.environ['GKE_CLUSTER_NAME'] = 'ksalama-cloudml-dev' # Set your GKE cluster name.\n",
    "os.environ['GKE_CLUSTER_ZONE'] = 'europe-west2-a' # Set your GKE cluster zone.\n",
    "\n",
    "os.environ['IMAGE_NAME'] = 'tfx-ml'\n",
    "os.environ['TAG'] = 'tfx0.25.0'\n",
    "os.environ['ML_IMAGE_URI']=f'gcr.io/{os.environ.get(\"PROJECT_ID\")}/{os.environ.get(\"IMAGE_NAME\")}:{os.environ.get(\"TAG\")}'\n",
    "\n",
    "os.environ['NAMESPACE'] = 'kubeflow-pipelines'\n",
    "os.environ['ARTIFACT_STORE_URI'] = f'gs://{os.environ.get(\"BUCKET\")}/tfx_artifact_store'\n",
    "os.environ['GCS_STAGING_PATH'] = f'{os.environ.get(\"ARTIFACT_STORE_URI\")}/staging'\n",
    "\n",
    "os.environ['RUNTIME_VERSION'] = '2.2'\n",
    "os.environ['PYTHON_VERSION'] = '3.7'\n",
    "os.environ['BEAM_RUNNER'] = 'DirectRunner'\n",
    "os.environ['MODEL_REGISTRY_URI'] = f'{os.environ.get(\"ARTIFACT_STORE_URI\")}/model_registry'\n",
    "\n",
    "os.environ['PIPELINE_NAME'] = 'tfx_bqml_scann'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx_pipeline import config\n",
    "\n",
    "for key, value in config.__dict__.items():\n",
    "  if key.isupper(): print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Pipeline Locally using Beam Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import tfx\n",
    "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
    "from tfx_pipeline import pipeline as pipeline_module\n",
    "import tensorflow as tf\n",
    "import ml_metadata as mlmd\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "print(\"TFX Version:\", tfx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_root = f'{config.ARTIFACT_STORE_URI}/{config.PIPELINE_NAME}_beamrunner'\n",
    "model_regisrty_uri = f'{config.MODEL_REGISTRY_URI}_beamrunner'\n",
    "local_mlmd_sqllite = 'mlmd/mlmd.sqllite'\n",
    "\n",
    "print(f'Pipeline artifacts root: {pipeline_root}')    \n",
    "print(f'Model registry location: {model_regisrty_uri}')  \n",
    "\n",
    "if tf.io.gfile.exists(pipeline_root):\n",
    "  print(\"Removing previous artifacts...\")\n",
    "  tf.io.gfile.rmtree(pipeline_root)\n",
    "if tf.io.gfile.exists('mlmd'):\n",
    "  print(\"Removing local mlmd SQLite...\")\n",
    "  tf.io.gfile.rmtree('mlmd')\n",
    "print(\"Creating mlmd directory...\")\n",
    "tf.io.gfile.mkdir('mlmd')\n",
    "\n",
    "metadata_connection_config = metadata_store_pb2.ConnectionConfig()\n",
    "metadata_connection_config.sqlite.filename_uri = local_mlmd_sqllite\n",
    "metadata_connection_config.sqlite.connection_mode = 3\n",
    "print(\"ML metadata store is ready.\")\n",
    "\n",
    "beam_pipeline_args = [\n",
    "  f'--runner=DirectRunner',\n",
    "  f'--project={config.PROJECT_ID}',\n",
    "  f'--temp_location={config.ARTIFACT_STORE_URI}/beam/tmp'\n",
    "]\n",
    "\n",
    "pipeline_module.SCHEMA_DIR = 'tfx_pipeline/schema'\n",
    "pipeline_module.LOOKUP_CREATOR_MODULE = 'tfx_pipeline/lookup_creator.py'\n",
    "pipeline_module.SCANN_INDEXER_MODULE = 'tfx_pipeline/scann_indexer.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BeamDagRunner()\n",
    "\n",
    "pipeline = pipeline_module.create_pipeline(\n",
    "  pipeline_name=config.PIPELINE_NAME,\n",
    "  pipeline_root=pipeline_root,\n",
    "  project_id=config.PROJECT_ID,\n",
    "  bq_dataset_name=config.BQ_DATASET_NAME,\n",
    "  min_item_frequency=15,\n",
    "  max_group_size=10,\n",
    "  dimensions=50,\n",
    "  num_leaves=500,\n",
    "  eval_min_recall=0.8,\n",
    "  eval_max_latency=0.001,\n",
    "  ai_platform_training_args=None,\n",
    "  beam_pipeline_args=beam_pipeline_args,\n",
    "  model_regisrty_uri=model_regisrty_uri,\n",
    "  metadata_connection_config=metadata_connection_config,\n",
    "  enable_cache=True\n",
    ")\n",
    "\n",
    "runner.run(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build Container Image\n",
    "\n",
    "The pipeline uses a custom docker image, which is a derivative of the [tensorflow/tfx:0.25.0](https://hub.docker.com/r/tensorflow/tfx) image, as a runtime execution environment for the pipeline's components. The same image is also used as a training image used by **AI Platform Training**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!gcloud builds submit --tag $ML_IMAGE_URI tfx_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compile TFX Pipeline using CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ${PIPELINE_NAME}.tar.gz\n",
    "!tfx pipeline compile \\\n",
    "    --engine=kubeflow \\\n",
    "    --pipeline_path=tfx_pipeline/runner.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy the Compiled Pipeline to KFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "gcloud container clusters get-credentials ${GKE_CLUSTER_NAME} --zone ${GKE_CLUSTER_ZONE}\n",
    "export KFP_ENDPOINT=$(kubectl describe configmap inverse-proxy-config -n ${NAMESPACE} | grep \"googleusercontent.com\")\n",
    "\n",
    "kfp --namespace=${NAMESPACE} --endpoint=${KFP_ENDPOINT} \\\n",
    "    pipeline upload \\\n",
    "    --pipeline-name=${PIPELINE_NAME} \\\n",
    "    ${PIPELINE_NAME}.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the KFP UI to run the deployed pipeline..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $(kubectl describe configmap inverse-proxy-config -n ${NAMESPACE} | grep \"googleusercontent.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"figures/kfp.png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "Copyright 2020 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License. You may obtain a copy of the License at: http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
    "\n",
    "See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "**This is not an official Google product but sample code provided for an educational purpose**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
